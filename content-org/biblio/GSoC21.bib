
@book{adamsFortran90Handbook1992,
  title = {Fortran 90 Handbook: Complete {{ANSI ISO}} Reference},
  shorttitle = {Fortran 90 Handbook},
  editor = {Adams, Jeanne C.},
  date = {1992},
  publisher = {{Intertext Publ. [u.a.]}},
  location = {{New York, NY}},
  isbn = {978-0-07-000406-1},
  langid = {english},
  pagetotal = {740},
  annotation = {OCLC: 246553971}
}

@article{backusHistoryFortranII1998,
  title = {The History of {{Fortran I}}, {{II}}, and {{III}}},
  author = {Backus, J.},
  date = {1998-10},
  journaltitle = {IEEE Annals of the History of Computing},
  volume = {20},
  number = {4},
  pages = {68--78},
  issn = {1934-1547},
  doi = {10.1109/85.728232},
  abstract = {The article discusses attitudes about "automatic programming", the economics of programming, and existing programming systems, all in the early 1950s. It describes the formation of the Fortran group, its knowledge of existing systems, its plans for Fortran, and the development of the language in 1954. It describes the development of the optimizing compiler for Fortran I, of various language manuals, and of Fortran II and III. It concludes with remarks about later developments and the impact of Fortran and its successors on programming today.},
  eventtitle = {{{IEEE Annals}} of the {{History}} of {{Computing}}},
  keywords = {Algorithms,Automatic programming,Computer aided instruction,Computer languages,Decision support systems,Environmental economics,History,Optimizing compilers,Program processors,Programming profession}
}

@inproceedings{benediktssonFORTRANIIFirst2009,
  title = {{{FORTRAN II}} – {{The First Computer Language Used}} at the {{University}} of {{Iceland}}},
  booktitle = {History of {{Nordic Computing}} 2},
  author = {Benediktsson, Oddur},
  editor = {Impagliazzo, John and Järvi, Timo and Paju, Petri},
  date = {2009},
  series = {{{IFIP Advances}} in {{Information}} and {{Communication Technology}}},
  pages = {149--155},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-03757-3_16},
  abstract = {At the end of World War II, people considered Iceland an underdeveloped country. The use of IBM punched card systems started in 1949. The first computers appeared in 1964. Then the University of Iceland acquired an IBM 1620 “scientific” computer. The first computer language used to instruct engineers and scientists was FORTRAN II. The subsequent development gives an interesting picture of the advance of computer technology in Iceland.},
  isbn = {978-3-642-03757-3},
  langid = {english},
  keywords = {FORTRAN II,IBM 1620,programming education}
}

@article{brisebarreNewRangeReductionAlgorithm2005,
  title = {A {{New Range-Reduction Algorithm}}},
  author = {Brisebarre, Nicolas and Defour, David and Kornerup, Peter and Muller, Jean-Michel},
  date = {2005},
  journaltitle = {IEEE TRANSACTIONS ON COMPUTERS},
  volume = {54},
  number = {3},
  pages = {9},
  abstract = {Range-reduction is a key point for getting accurate elementary function routines. We introduce a new algorithm that is fast for input arguments belonging to the most common domains, yet accurate over the full double-precision range.},
  langid = {english}
}

@article{certikDftatomRobustGeneral2013,
  title = {Dftatom: {{A}} Robust and General {{Schrödinger}} and {{Dirac}} Solver for Atomic Structure Calculations},
  shorttitle = {Dftatom},
  author = {Čertík, Ondřej and Pask, John E. and Vackář, Jiří},
  date = {2013-07-01},
  journaltitle = {Computer Physics Communications},
  shortjournal = {Computer Physics Communications},
  volume = {184},
  number = {7},
  pages = {1777--1791},
  issn = {0010-4655},
  doi = {10.1016/j.cpc.2013.02.014},
  url = {https://www.sciencedirect.com/science/article/pii/S0010465513000714},
  urldate = {2021-04-26},
  abstract = {A robust and general solver for the radial Schrödinger, Dirac, and Kohn–Sham equations is presented. The formulation admits general potentials and meshes: uniform, exponential, or other defined by nodal distribution and derivative functions. For a given mesh type, convergence can be controlled systematically by increasing the number of grid points. Radial integrations are carried out using a combination of asymptotic forms, Runge–Kutta, and implicit Adams methods. Eigenfunctions are determined by a combination of bisection and perturbation methods for robustness and speed. An outward Poisson integration is employed to increase accuracy in the core region, allowing absolute accuracies of 10−8 Hartree to be attained for total energies of heavy atoms such as uranium. Detailed convergence studies are presented and computational parameters are provided to achieve accuracies commonly required in practice. Comparisons to analytic and current-benchmark density-functional results for atomic number Z=1–92 are presented, verifying and providing a refinement to current benchmarks. An efficient, modular Fortran 95 implementation, dftatom, is provided as open source, including examples, tests, and wrappers for interface to other languages; wherein particular emphasis is placed on the independence (no global variables), reusability, and generality of the individual routines. Program summary Program title:dftatom Catalogue identifier: AEPA\_v1\_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AEPA\_v1\_0.html Program obtainable from: CPC Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: MIT license No. of lines in distributed program, including test data, etc.: 14122 No. of bytes in distributed program, including test data, etc.: 157453 Distribution format: tar.gz Programming language: Fortran 95 with interfaces to Python and C. Computer: Any computer with a Fortran 95 compiler. Operating system: Any OS with a Fortran 95 compiler. RAM: 500~MB Classification: 2.1. External routines: Numpy (http://www.numpy.org/) and Cython (http://cython.org/) Nature of problem: Solution of the Schrödinger, Dirac, and Kohn–Sham equations of Density Functional Theory for isolated atoms. Solution method: Radial integrations are carried out using a combination of asymptotic forms, Runge–Kutta, and implicit Adams methods. Eigenfunctions are determined by a combination of bisection and perturbation methods. An outward Poisson integration is employed to increase accuracy in the core region. Self-consistent field equations are solved by adaptive linear mixing. Restrictions: Spherical symmetry Unusual features: Radial integrators work for general potentials and meshes. No restriction to Coulombic or self-consistent potentials; no restriction to uniform or exponential meshes. Outward Poisson integration. Fallback to bisection for robustness. Running time: For uranium, non-relativistic density functional calculation execution time is around 0.6~s for 10−6 a.u. accuracy in total energy on an Intel Core i7 1.46~GHz processor.},
  langid = {english},
  keywords = {Atomic structure,Density functional theory,Dirac equation,Electronic structure,Fortran 95,Kohn–Sham equations,Schrödinger equation,Shooting method}
}

@article{chevillardEfficientAccurateComputation2011,
  title = {Efficient and Accurate Computation of Upper Bounds of Approximation Errors},
  author = {Chevillard, S. and Harrison, J. and Joldeş, M. and Lauter, Ch.},
  date = {2011-04-01},
  journaltitle = {Theoretical Computer Science},
  shortjournal = {Theoretical Computer Science},
  series = {Symbolic and {{Numerical Algorithms}}},
  volume = {412},
  number = {16},
  pages = {1523--1543},
  issn = {0304-3975},
  doi = {10.1016/j.tcs.2010.11.052},
  url = {https://www.sciencedirect.com/science/article/pii/S0304397510006900},
  urldate = {2021-08-19},
  abstract = {For purposes of actual evaluation, mathematical functions f are commonly replaced by approximation polynomials p. Examples include floating-point implementations of elementary functions, quadrature or more theoretical proof work involving transcendental functions. Replacing f by p induces a relative error ϵ=p/f−1. In order to ensure the validity of the use of p instead of f, the maximum error, i.e.~the supremum norm ‖ϵ‖∞I must be safely bounded above over an interval I, whose width is typically of order 1. Numerical algorithms for supremum norms are efficient, but they cannot offer the required safety. Previous validated approaches often require tedious manual intervention. If they are automated, they have several drawbacks, such as the lack of quality guarantees. In this article, a novel, automated supremum norm algorithm on univariate approximation errors ϵ is proposed, achieving an a priori quality on the result. It focuses on the validation step and paves the way for formally certified supremum norms. Key elements are the use of intermediate approximation polynomials with bounded approximation error and a non-negativity test based on a sum-of-squares expression of polynomials. The new algorithm was implemented in the Sollya tool. The article includes experimental results on real-life examples.},
  langid = {english},
  keywords = {Approximation error,Certification,Formal proof,Sum of squares,Supremum norm,Taylor models,Validation}
}

@inproceedings{chevillardSollyaEnvironmentDevelopment2010,
  title = {Sollya: {{An}} Environment for the Development of Numerical Codes},
  booktitle = {Mathematical Software - {{ICMS}} 2010},
  author = {Chevillard, S. and Joldeş, M. and Lauter, C.},
  editor = {Fukuda, K. and van der Hoeven, J. and Joswig, M. and Takayama, N.},
  options = {useprefix=true},
  date = {2010-09},
  series = {Lecture Notes in Computer Science},
  volume = {6327},
  pages = {28--31},
  publisher = {{Springer}},
  location = {{Heidelberg, Germany}},
  abstract = {Sollya has become a mature tool for the development of numerical software. With about 175 built-in algorithms and a broad extensibility, it offers a complete tool-chain for fixed- and floating-point software and hardware design. Its features include on-the-fly faithful rounding, specialized approximation algorithms and extensive support for floating-point code generation.},
  keywords = {computer algebra,development tool,faithful rounding,function approximation,numerical software}
}

@article{cipraBest20thCentury,
  title = {The {{Best}} of the 20th {{Century}}: {{Editors Name Top}} 10 {{Algorithms}}},
  author = {Cipra, Barry A},
  pages = {2},
  langid = {english}
}

@book{clermanModernFortranStyle2012,
  title = {Modern {{Fortran}}: Style and Usage},
  shorttitle = {Modern {{Fortran}}},
  author = {Clerman, Norman S. and Spector, Walter},
  date = {2012},
  publisher = {{Cambridge University Press}},
  location = {{New York}},
  isbn = {978-0-521-51453-8 978-0-521-73052-5},
  pagetotal = {334},
  keywords = {FORTRAN (Computer program language)},
  annotation = {OCLC: ocn743298762}
}

@book{cooperEngineeringCompiler2011a,
  title = {Engineering a {{Compiler}}},
  author = {Cooper, Keith and Torczon, Linda},
  date = {2011-01-18},
  eprint = {_tgh4bgQ6PAC},
  eprinttype = {googlebooks},
  publisher = {{Elsevier}},
  abstract = {This entirely revised second edition of Engineering a Compiler is full of technical updates and new material covering the latest developments in compiler technology. In this comprehensive text you will learn important techniques for constructing a modern compiler. Leading educators and researchers Keith Cooper and Linda Torczon combine basic principles with pragmatic insights from their experience building state-of-the-art compilers. They will help you fully understand important techniques such as compilation of imperative and object-oriented languages, construction of static single assignment forms, instruction scheduling, and graph-coloring register allocation.In-depth treatment of algorithms and techniques used in the front end of a modern compilerFocus on code optimization and code generation, the primary areas of recent research and developmentImprovements in presentation including conceptual overviews for each chapter, summaries and review questions for sections, and prominent placement of definitions for new termsExamples drawn from several different programming languages},
  isbn = {978-0-08-091661-3},
  langid = {english},
  pagetotal = {825},
  keywords = {Computers / Computer Architecture,Computers / Computer Engineering,Computers / General,Computers / Languages / General,Computers / Operating Systems / General,Computers / Programming / Compilers,Computers / Software Development & Engineering / General}
}

@article{defourNewRangeReduction,
  title = {A New Range Reduction Algorithm},
  author = {Defour, P David and Kornerup, Peter and Muller, Jean-Michel and Revol, Nathalie},
  pages = {13}
}

@inproceedings{detreyParameterizedFloatingpointExponential2005,
  title = {A Parameterized Floating-Point Exponential Function for {{FPGAs}}},
  booktitle = {Proceedings. 2005 {{IEEE International Conference}} on {{Field-Programmable Technology}}, 2005.},
  author = {Detrey, J. and de Dinechin, F.},
  options = {useprefix=true},
  date = {2005},
  pages = {27--34},
  publisher = {{IEEE}},
  location = {{Singapore, China}},
  doi = {10.1109/FPT.2005.1568520},
  url = {http://ieeexplore.ieee.org/document/1568520/},
  urldate = {2021-08-19},
  abstract = {A parameterized floating-point exponential operator is presented. In single-precision, it uses a small fraction of the FPGA’s resources and has a smaller latency than its software equivalent on a high-end processor, and ten times the throughput in pipelined version. Previous work had shown that FPGAs could use massive parallelism to balance the poor performance of their basic floating-point operators compared to the equivalent in processors. As this work shows, when evaluating an elementary function, the flexibility of FPGAs provides much better performance than the processor witout even resorting to parallelism.},
  eventtitle = {2005 {{IEEE International Conference}} on {{Field-Programmable Technology}}, 2005.},
  isbn = {978-0-7803-9407-0},
  langid = {english}
}

@inproceedings{dong-uleeAdaptiveRangeReduction2004,
  title = {Adaptive Range Reduction for Hardware Function Evaluation},
  booktitle = {Proceedings. 2004 {{IEEE International Conference}} on {{Field- Programmable Technology}} ({{IEEE Cat}}. {{No}}.{{04EX921}})},
  author = {{Dong-U Lee} and Gaffar, A.A. and Mencer, O. and Luk, W.},
  date = {2004},
  pages = {169--176},
  publisher = {{IEEE}},
  location = {{Brisbane, NSW, Australia}},
  doi = {10.1109/FPT.2004.1393265},
  url = {http://ieeexplore.ieee.org/document/1393265/},
  urldate = {2021-08-18},
  eventtitle = {2004 {{IEEE International Conference}} on {{Field- Programmable Technology}}},
  isbn = {978-0-7803-8651-8},
  langid = {english}
}

@article{evenDesignIEEECompliant,
  title = {On {{The Design}} of {{IEEE Compliant Floating Point Units}}},
  author = {Even, Guy and Paul, Wolfgang},
  pages = {25},
  abstract = {Engineering design methodology recommends designing a system as follows: Start with an unambiguous speci cation, partition the system into blocks, specify the functionality of each block, design each block separately, and glue the blocks together. Verifying the correctness of an implementation reduces then to a local veri cation procedure.},
  langid = {english}
}

@article{fergusonDifferenceX87Instructions2015,
  title = {The {{Difference Between}} X87 {{Instructions FSIN}}, {{FCOS}}, {{FSINCOS}}, and {{FPTAN}} and {{Mathematical Functions}} Sin, Cos, Sincos, and Tan},
  author = {Ferguson, Warren and Cornea, Marius and Anderson, Cristina and Schneider, Eric},
  date = {2015},
  pages = {6},
  langid = {english}
}

@article{gillProcessStepbystepIntegration1951,
  title = {A Process for the Step-by-Step Integration of Differential Equations in an Automatic Digital Computing Machine},
  author = {Gill, S.},
  date = {1951-01},
  journaltitle = {Mathematical Proceedings of the Cambridge Philosophical Society},
  volume = {47},
  number = {1},
  pages = {96--108},
  publisher = {{Cambridge University Press}},
  issn = {1469-8064, 0305-0041},
  doi = {10.1017/S0305004100026414},
  url = {https://www.cambridge.org/core/journals/mathematical-proceedings-of-the-cambridge-philosophical-society/article/abs/process-for-the-stepbystep-integration-of-differential-equations-in-an-automatic-digital-computing-machine/39FD4351E30AD4588E2F9C001665C62D},
  urldate = {2021-08-19},
  abstract = {It is advantageous in automatic computers to employ methods of integration which do not require preceding function values to be known. From a general theory given by Kutta, one such process is chosen giving fourth-order accuracy and requiring the minimum number of storage registers. It is developed into a form which gives the highest attainable accuracy and can be carried out by comparatively few instructions. The errors are studied and a simple example is given.},
  langid = {english}
}

@article{goldbergWhatEveryComputer1991,
  title = {What Every Computer Scientist Should Know about Floating-Point Arithmetic},
  author = {Goldberg, David},
  date = {1991-03},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {23},
  number = {1},
  pages = {5--48},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/103162.103163},
  url = {https://dl.acm.org/doi/10.1145/103162.103163},
  urldate = {2021-08-13},
  abstract = {Floating-point arithmetic is considered as esoteric subject by many people. This is rather surprising, because floating-point is ubiquitous in computer systems: Almost every language has a floating-point datatype; computers from PCs to supercomputers have floating-point accelerators; most compilers will be called upon to compile floating-point algorithms from time to time; and virtually every operating system must respond to floating-point exceptions such as overflow. This paper presents a tutorial on the aspects of floating-point that have a direct impact on designers of computer systems. It begins with background on floating-point representation and rounding error, continues with a discussion of the IEEE floating point standard, and concludes with examples of how computer system builders can better support floating point.},
  langid = {english}
}

@online{hansonEarlyExperienceASDL1998,
  title = {Early {{Experience}} with {{ASDL}} in Lcc},
  author = {Hanson, David R.},
  date = {1998-10-13},
  eprint = {cs/9810013},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/cs/9810013},
  urldate = {2021-07-05},
  abstract = {The Abstract Syntax Description Language (ASDL) is a language for specifying the tree data structures often found in compiler intermediate representations. The ASDL generator reads an ASDL specification and generates code to construct, read, and write instances of the trees specified. Using ASDL permits a compiler to be decomposed into semi-independent components that communicate by reading and writing trees. Each component can be written in a different language, because the ASDL generator can emit code in several languages, and the files written by ASDL-generated code are machine- and language-independent. ASDL is part of the National Compiler Infrastructure project, which seeks to reduce dramatically the overhead of computer systems research by making it much easier to build highquality compilers. This paper describes dividing lcc, a widely used retargetable C compiler, into two components that communicate via trees defined in ASDL. As the first use of ASDL in a ‘real’ compiler, this experience reveals much about the effort required to retrofit an existing compiler to use ASDL, the overheads involved, and the strengths and weaknesses of ASDL itself and, secondarily, of lcc.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Programming Languages,Computer Science - Software Engineering,D.3.4}
}

@report{IEEEStandardRadixIndependent,
  title = {{{IEEE Standard}} for {{Radix-Independent Floating-Point Arithmetic}}},
  institution = {{IEEE}},
  doi = {10.1109/IEEESTD.1987.81037},
  url = {http://ieeexplore.ieee.org/document/27840/},
  urldate = {2021-08-15},
  isbn = {9780738111674},
  langid = {english}
}

@article{IEEEStd7542008,
  title = {{{IEEE Std}} 754™-2008 ({{Revision}} of {{IEEE Std}} 754-1985), {{IEEE Standard}} for {{Floating-Point Arithmetic}}},
  date = {2008},
  pages = {70},
  abstract = {Abstract: This standard specifies interchange and arithmetic formats and methods for binary and decimal floating-point arithmetic in computer programming environments. This standard specifies exception conditions and their default handling. An implementation of a floating-point system conforming to this standard may be realized entirely in software, entirely in hardware, or in any combination of software and hardware. For operations specified in the normative part of this standard, numerical results and exceptions are uniquely determined by the values of the input data, sequence of operations, and destination formats, all under user control.},
  langid = {english}
}

@report{ISOIECSTANDARD,
  title = {({{ISO}}/{{IEC STANDARD}} 10967-2) {{Information}} Technology — {{Language}} Independent Arithmetic — {{Part}} 2: {{Elementary}} Numerical Functions},
  url = {http://www.open-std.org/JTC1/SC22/WG11/docs/n462.pdf},
  urldate = {2021-08-13},
  abstract = {ISO (the International Organization for Standardization) and IEC (the International Electrotechnical Commission) form the specialised system for world-wide standardization. National bodies that are members of ISO or IEC participate in the development of International Standards through technical committees established by the respective organization to deal with particular fields of technical activity. ISO and IEC technical committees collaborate in fields of mutual interest. Other international organisations, governmental and non-governmental, in liaison with ISO and IEC, also take part in the work. In the field of information technology, ISO and IEC have established a joint technical committee, ISO/IEC JTC 1, Implementation of information technology. Draft International Standards adopted by the joint technical committee are circulated to national bodies for voting. Publication as an International Standard requires approval by at least 75 \% of the national bodies casting a vote. International Standard ISO/IEC 10967-2 was prepared by Joint Technical Committee ISO/IEC JTC 1, Sub-Committee SC 22, Programming languages, their environments and system software interfaces. ISO/IEC 10967 consists of the following parts, under the general title Information technology — Language independent arithmetic: – Part 1: Integer and floating point arithmetic – Part 2: Elementary numerical functions – Part 3: Complex floating point arithmetic and complex elementary numerical functions Additional parts will specify other arithmetic datatypes or arithmetic operations.}
}

@report{J318007r1F2018,
  title = {J3/18-007r1 ({{F2018 Interpretation Document}})},
  url = {https://j3-fortran.org/doc/year/18/18-007r1.pdf},
  urldate = {2021-06-28},
  abstract = {9th October 2018 16:46}
}

@report{J321007Draft,
  title = {J3/21-007 ({{Draft Fortran}} 202x)},
  url = {https://j3-fortran.org/doc/year/21/21-007.pdf},
  urldate = {2021-06-28},
  abstract = {16th December 2020 12:00}
}

@report{J397007R295,
  title = {J3/97-{{007R2}} (95 {{Interpretation Document}})},
  url = {https://j3-fortran.org/doc/year/18/18-007r1.pdf},
  urldate = {2021-06-28},
  abstract = {October 21, 1997 12:28 pm}
}

@inproceedings{johanssonEfficientImplementationElementary2015,
  title = {Efficient Implementation of Elementary Functions in the Medium-Precision Range},
  booktitle = {22nd {{IEEE Symposium}} on {{Computer Arithmetic}} ({{ARITH22}})},
  author = {Johansson, Fredrik},
  date = {2015-06},
  location = {{Lyon, France}},
  doi = {10.1109/ARITH.2015.16},
  url = {https://hal.archives-ouvertes.fr/hal-01079834},
  urldate = {2021-09-17},
  abstract = {We describe a new implementation of the elementary transcendental functions exp, sin, cos, log and atan for variable precision up to approximately 4096 bits. Compared to the MPFR library, we achieve a maximum speedup ranging from a factor 3 for cos to 30 for atan. Our implementation uses table-based argument reduction together with rectangular splitting to evaluate Taylor series. We collect denominators to reduce the number of divisions in the Taylor series, and avoid overhead by doing all multiprecision arithmetic using the mpn layer of the GMP library. Our implementation provides rigorous error bounds.}
}

@article{kahanIEEEStandard7541997,
  title = {{{IEEE Standard}} 754 for {{Binary Floating-Point Arithmetic}}},
  author = {Kahan, W},
  date = {1997},
  pages = {30},
  langid = {english}
}

@article{khedkerGCCTranslationSequence,
  title = {{{GCC Translation Sequence}} and {{Gimple IR}}},
  author = {Khedker, Uday},
  pages = {70},
  langid = {english}
}

@article{klintEngineeringDisciplineGrammarware2005,
  title = {Toward an Engineering Discipline for Grammarware},
  author = {Klint, Paul and Lämmel, Ralf and Verhoef, Chris},
  date = {2005-07-01},
  journaltitle = {ACM Transactions on Software Engineering and Methodology},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  volume = {14},
  number = {3},
  pages = {331--380},
  issn = {1049-331X},
  doi = {10.1145/1072997.1073000},
  url = {https://doi.org/10.1145/1072997.1073000},
  urldate = {2021-07-05},
  abstract = {Grammarware comprises grammars and all grammar-dependent software. The term grammar is meant here in the sense of all established grammar formalisms and grammar notations including context-free grammars, class dictionaries, and XML schemas as well as some forms of tree and graph grammars. The term grammar-dependent software refers to all software that involves grammar knowledge in an essential manner. Archetypal examples of grammar-dependent software are parsers, program converters, and XML document processors. Despite the pervasive role of grammars in software systems, the engineering aspects of grammarware are insufficiently understood. We lay out an agenda that is meant to promote research on increasing the productivity of grammarware development and on improving the quality of grammarware. To this end, we identify the problems with the current grammarware practices, the barriers that currently hamper research, and the promises of an engineering discipline for grammarware, its principles, and the research challenges that have to be addressed.},
  keywords = {automated software engineering,best practices,generic language technology,grammar-dependent software,grammars,Grammarware,language processing,metamodeling,model-driven development,parsers,software evolution,software transformation}
}

@book{levineLinkersLoaders2000,
  title = {Linkers and Loaders},
  author = {Levine, John R.},
  date = {2000},
  publisher = {{Morgan Kaufmann}},
  location = {{San Francisco}},
  isbn = {978-1-55860-496-4},
  pagetotal = {256},
  keywords = {Assembling (Electronic computers),Linkers (Computer programs),Loaders (Computer programs)}
}

@book{lyonUsingAnsFortran1980,
  title = {Using {{Ans Fortran}}},
  author = {Lyon, G. E.},
  date = {1980},
  eprint = {8ymHAQAACAAJ},
  eprinttype = {googlebooks},
  publisher = {{National Bureau of Standards}},
  abstract = {This FORTRAN volume presents, in order: a set of quick and clear reference charts for ANS FORTRAN 66 syntax; observations on using only standard FORTRAN 65 features; instructions on circumventing and extending FORTRAN 66 with the least harm; an appraisal of the new FORTRAN 77 in terms of FORTRAN 65 constructs. Although the chapters comprise much material that has appeared in other technical memoranda or published articles, heavily recast sections have been re-refereed. The four chapters address programmers concerned with FORTRAN transportability, managers engaged in programming standards, and other practitioners interested in system influences upon languages. Since the text touches upon several general programming aspects (input/output, storage allocation, storage lifetimes and protection, control structures), the volume's appeal will extend beyond the immediate FORTRAN community.},
  langid = {english},
  pagetotal = {109}
}

@article{mccalpinCaseSmdyIssues,
  title = {A {{Case Smdy}} of {{Some Issues}} in the {{Optimization}} of {{Fortran}} 90 {{Array Notation}}},
  author = {McCALPIN, JOHN D},
  pages = {20},
  abstract = {Some issues in the relationship of coding style and compiler optimization are discussed with regard to Fortran 90 array notation. A review of several important Fortran 90 array constructs and their performance on vector and scalar hardware sets the stage for a more detailed example based on the kernel of a finite difference computational fluid dynamics model, specifically the nonlinear shallow water equations. Special attention is paid to the optimization of memory use and memory traffic. It is shown that the style of coding interacts with the rules of Fortran 90 and the current state of the art of Fortran 90 compilers to produce a fairly wide range of performance levels. Although performance degradations are typically small, a few cases of more serious loss of effciency are identified and discussed. © 1996 John Wiley \& Sons, Inc.},
  langid = {english}
}

@article{merrillGENERICGIMPLENew,
  title = {{{GENERIC}} and {{GIMPLE}}: {{A New Tree Representation}} for {{Entire Functions}}},
  author = {Merrill, Jason},
  pages = {10},
  langid = {english}
}

@book{mullerElementaryFunctions2016,
  title = {Elementary {{Functions}}},
  author = {Muller, Jean-Michel},
  date = {2016},
  publisher = {{Birkhäuser Boston}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7983-4},
  url = {http://link.springer.com/10.1007/978-1-4899-7983-4},
  urldate = {2021-08-13},
  isbn = {978-1-4899-7981-0 978-1-4899-7983-4},
  langid = {english}
}

@book{mullerHandbookFloatingPointArithmetic2018,
  title = {Handbook of {{Floating-Point Arithmetic}}},
  author = {Muller, Jean-Michel and Brunie, Nicolas and de Dinechin, Florent and Jeannerod, Claude-Pierre and Joldes, Mioara and Lefèvre, Vincent and Melquiond, Guillaume and Revol, Nathalie and Torres, Serge},
  options = {useprefix=true},
  date = {2018},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-76526-6},
  url = {http://link.springer.com/10.1007/978-3-319-76526-6},
  urldate = {2021-08-13},
  isbn = {978-3-319-76525-9 978-3-319-76526-6},
  langid = {english}
}

@article{ngArgumentReductionHuge2006,
  title = {Argument {{Reduction}} for {{Huge Arguments}}: {{Good}} to the Last Bit},
  author = {Ng, K C},
  date = {2006},
  journaltitle = {. Introduction},
  pages = {8},
  langid = {english}
}

@book{overtonNumericalComputingIEEE2001,
  title = {Numerical Computing with {{IEEE}} Floating Point Arithmetic: Including One Theorem, One Rule of Thumb, and One Hundred and One Exercises},
  shorttitle = {Numerical Computing with {{IEEE}} Floating Point Arithmetic},
  author = {Overton, Michael L.},
  date = {2001},
  publisher = {{SIAM, Society for Industrial and Applied Mathematics}},
  location = {{Philadelphia, PA}},
  isbn = {978-0-89871-571-2},
  langid = {english},
  pagetotal = {106}
}

@article{papaevripidesExploitingMixedBinaries2021,
  title = {Exploiting {{Mixed Binaries}}},
  author = {Papaevripides, Michalis and Athanasopoulos, Elias},
  date = {2021-02},
  journaltitle = {ACM Transactions on Privacy and Security},
  shortjournal = {ACM Trans. Priv. Secur.},
  volume = {24},
  number = {2},
  pages = {1--29},
  issn = {2471-2566, 2471-2574},
  doi = {10.1145/3418898},
  url = {https://dl.acm.org/doi/10.1145/3418898},
  urldate = {2021-07-07},
  abstract = {Unsafe programming systems are still very popular, despite the shortcomings due to several published memory-corruption vulnerabilities. Toward defending memory corruption, compilers have started to employ advanced software hardening such as Control-flow Integrity (CFI) and SafeStack. However, there is a broad interest for realizing compilers that impose memory safety with no heavy runtime support (e.g., garbage collection). Representative examples of this category are Rust and Go, which enforce memory safety primarily statically at compile time.                            Software hardening and Rust/Go are promising directions for defending memory corruption, albeit combining the two is questionable. In this article, we consider hardened               mixed               binaries, i.e., machine code that has been produced from different compilers and, in particular, from               hardened               C/C++ and Rust/Go (e.g., Mozilla Firefox, Dropbox, npm, and Docker). Our analysis is focused on Mozilla Firefox, which outsources significant code to Rust and is open source with known public vulnerabilities (with assigned CVE). Furthermore, we extend our analysis in mixed binaries that leverage Go, and we derive similar results.                                         The attacks explored in this article               do not               exploit Rust or Go binaries that depend on some legacy (vulnerable) C/C++ code. In contrast, we explore how Rust/Go compiled code can stand as a vehicle for bypassing hardening in C/C++ code. In particular, we discuss CFI and SafeStack, which are available in the latest Clang. Our assessment concludes that CFI can be completely nullified through Rust or Go code by constructing much simpler attacks than state-of-the-art CFI bypasses.},
  langid = {english}
}

@article{payneRadianReductionTrigonometric1983a,
  title = {Radian Reduction for Trigonometric Functions},
  author = {Payne, Mary H. and Hanek, Robert N.},
  date = {1983-01},
  journaltitle = {ACM SIGNUM Newsletter},
  shortjournal = {SIGNUM Newsl.},
  volume = {18},
  number = {1},
  pages = {19--24},
  issn = {0163-5778},
  doi = {10.1145/1057600.1057602},
  url = {https://dl.acm.org/doi/10.1145/1057600.1057602},
  urldate = {2021-08-13},
  abstract = {An accurate reduction poses little difficulty for arguments of a few radians. However for, say, a CRAY1, H format on the VAX, or double extended in the proposed IEEE standard, the maximum argument which might be presented for reduction is of the order of 2\^16000 radians. Accurate reduction of such an argument would require storage of π (or its reciprocal) to over 16,000 bits. Direct reduction by division (or multiplication) then requires generation of a somewhat larger number of bits in the result in order to guarantee the accuracy of the reduction. Of these bits only the low few bits of the integer part of the quotient (product) and enough bits to correctly round the remainder are relevant; the rest will be discarded.},
  langid = {english}
}

@article{rumpRigorousPortableStandard2001,
  title = {Rigorous and {{Portable Standard Functions}}},
  author = {Rump, Siegfried M.},
  date = {2001-06-01},
  journaltitle = {BIT Numerical Mathematics},
  shortjournal = {BIT Numerical Mathematics},
  volume = {41},
  number = {3},
  pages = {540--562},
  issn = {1572-9125},
  doi = {10.1023/A:1021971313412},
  url = {https://doi.org/10.1023/A:1021971313412},
  urldate = {2021-08-18},
  abstract = {Today's floating point implementations of elementary transcendental functions are usually very accurate. However, with few exceptions, the actual accuracy is not known. In the present paper we describe a rigorous, accurate, fast and portable implementation of the elementary standard functions based on some existing approximate standard functions. The scheme is outlined for IEEE 754, but not difficult to adapt to other floating point formats. A Matlab implementation is available on the net. Accuracy of the proposed algorithms can be rigorously estimated. As an example we prove that the relative accuracy of the exponential function is better than 2.07 eps in a slightly reduced argument range (eps denoting the relative rounding error unit). Otherwise, extensive computational tests suggest for all elementary functions and all suitable arguments an accuracy better than about 3 eps.},
  langid = {english}
}

@article{tangFrameworkLowcommunication,
  title = {A Framework for Low-Communication},
  author = {Tang, Ping Tak Peter and Park, Jongsoo and Kim, Daehyun and Petrov, Vladimir},
  pages = {16},
  abstract = {In high-performance computing on distributed-memory systems, communication often represents a significant part of the overall execution time. The relative cost of communication will certainly continue to rise as compute-density growth follows the current technology and industry trends. Design of lower-communication alternatives to fundamental computational algorithms has become an important field of research. For distributed 1-D FFT, communication cost has hitherto remained high as all industry-standard implementations perform three all-to-all internode data exchanges (also called global transposes). These communication steps indeed dominate execution time. In this paper, we present a mathematical framework from which many single-all-to-all and easy-to-implement 1-D FFT algorithms can be derived. For large-scale problems, our implementation can be twice as fast as leading FFT libraries on state-of-the-art computer clusters. Moreover, our framework allows tradeoff between accuracy and performance, further boosting performance if reduced accuracy is acceptable.},
  langid = {english}
}

@article{tasissaFUNCTIONAPPROXIMATIONREMEZ,
  title = {{{FUNCTION APPROXIMATION AND THE REMEZ ALGORITHM}}},
  author = {Tasissa, Abiy},
  pages = {12},
  abstract = {The Remez exchange algorithm is explained. An implementation in Python is tested on different test functions. We make a comparison with SLSQP(Sequential Least Squares Programming) optimizer.},
  langid = {english}
}

@online{UsingASDLDescribe,
  title = {Using {{ASDL}} to Describe {{ASTs}} in Compilers - {{Eli Bendersky}}'s Website},
  url = {https://eli.thegreenplace.net/2014/06/04/using-asdl-to-describe-asts-in-compilers/},
  urldate = {2021-07-05}
}

@article{wangZephyrAbstractSyntax,
  title = {The {{Zephyr Abstract Syntax Description Language}}},
  author = {Wang, Daniel C and Appel, Andrew W and Korn, Jeff L and Serra, Christopher S},
  pages = {16},
  abstract = {The Zephyr1 Abstract Syntax Description Language (ASDL) describes the abstract syntax of compiler intermediate representations (IRs) and other tree-like data structures. Just as the lexical and syntactic structures of programming languages are described with regular expressions and context free grammars, ASDL provides a concise notation for describing the abstract syntax of programming languages. Tools can convert ASDL descriptions into the appropriate data-structure definitions and functions to convert the data-structures to or from a standard flattened representation. This makes it easier to build compiler components that interoperate.},
  langid = {english}
}

@article{zhouEmpiricalStudyOptimization2021,
  title = {An Empirical Study of Optimization Bugs in {{GCC}} and {{LLVM}}},
  author = {Zhou, Zhide and Ren, Zhilei and Gao, Guojun and Jiang, He},
  date = {2021-04-01},
  journaltitle = {Journal of Systems and Software},
  shortjournal = {Journal of Systems and Software},
  volume = {174},
  pages = {110884},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2020.110884},
  url = {https://www.sciencedirect.com/science/article/pii/S0164121220302740},
  urldate = {2021-07-09},
  abstract = {Optimizations are the fundamental component of compilers. Bugs in optimizations have significant impacts, and can cause unintended application behavior and disasters, especially for safety-critical domains. Thus, an in-depth analysis of optimization bugs should be conducted to help developers understand and test the optimizations in compilers. To this end, we conduct an empirical study to investigate the characteristics of optimization bugs in two mainstream compilers, GCC and LLVM. We collect about 57K and 22K bugs of GCC and LLVM, and then exhaustively examine 8,771 and 1,564 optimization bugs of the two compilers, respectively. The results reveal the following five characteristics of optimization bugs: (1) Optimizations are the buggiest component in both compilers except for the C++ component; (2) the value range propagation optimization and the instruction combine optimization are the buggiest optimizations in GCC and LLVM, respectively; the loop optimizations in both GCC and LLVM are more bug-prone than other optimizations; (3) most of the optimization bugs in both GCC and LLVM are misoptimization bugs, accounting for 57.21\% and 61.38\% respectively; (4) on average, the optimization bugs live over five months, and developers take 11.16 months for GCC and 13.55 months for LLVM to fix an optimization bug; in both GCC and LLVM, many confirmed optimization bugs have lived for a long time; (5) the bug fixes of optimization bugs involve no more than two files and three functions on average in both compilers, and around 99\% of them modify no more than 100 lines of code, while 90\% less than 50 lines of code. Our study provides a deep understanding of optimization bugs for developers and researchers. This could provide useful guidance for the developers and researchers to better design the optimizations in compilers. In addition, the analysis results suggest that we need more effective techniques and tools to test compiler optimizations. Moreover, our findings are also useful to the research of automatic debugging techniques for compilers, such as automatic compiler bug isolation techniques.},
  langid = {english},
  keywords = {Bug characteristics,Compiler optimization bugs,Compiler reliability,Compiler testing,Empirical study}
}


