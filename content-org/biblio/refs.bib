@article{betancourtConceptualIntroductionHamiltonian2018,
  title           = {A {{Conceptual Introduction}} to {{Hamiltonian Monte
                  Carlo}}},
  author          = {Betancourt, Michael},
  date            = {2018-07-15},
  url             = {http://arxiv.org/abs/1701.02434},
  urldate         = {2020-04-03},
  abstract        = {Hamiltonian Monte Carlo has proven a remarkable empirical
                  success, but only recently have we begun to develop a rigorous
                  understanding of why it performs so well on difficult problems
                  and how it is best applied in practice. Unfortunately, that
                  understanding is confined within the mathematics of
                  differential geometry which has limited its dissemination,
                  especially to the applied communities for which it is
                  particularly important. In this review I provide a
                  comprehensive conceptual account of these theoretical
                  foundations, focusing on developing a principled intuition
                  behind the method and its optimal implementations rather of
                  any exhaustive rigor. Whether a practitioner or a
                  statistician, the dedicated reader will acquire a solid grasp
                  of how Hamiltonian Monte Carlo works, when it succeeds, and,
                  perhaps most importantly, when it fails.},
  annotation      = {Comment: 60 pages, 42 figures},
  archivePrefix   = {arXiv},
  eprint          = {1701.02434},
  eprinttype      = {arxiv},
  keywords        = {Statistics - Methodology},
  primaryClass    = {stat}
}

@book{boydIntroductionAppliedLinear2018,
  title           = {Introduction to {{Applied Linear Algebra}}: {{Vectors}},
                  {{Matrices}}, and {{Least Squares}}},
  shorttitle      = {Introduction to {{Applied Linear Algebra}}},
  author          = {Boyd, Stephen and Vandenberghe, Lieven},
  date            = {2018-06-07},
  edition         = 1,
  publisher       = {{Cambridge University Press}},
  doi             = {10.1017/9781108583664},
  url             =
                  {https://www.cambridge.org/core/product/identifier/9781108583664/type/book},
  urldate         = {2020-02-29},
  isbn            = {978-1-108-58366-4},
  langid          = {english}
}

@article{breimanBaggingPredictors1996,
  title           = {Bagging {{Predictors}}},
  author          = {Breiman, Leo},
  date            = {1996-08-01},
  journaltitle    = {Machine Learning},
  shortjournal    = {Machine Learning},
  volume          = 24,
  pages           = {123--140},
  issn            = {1573-0565},
  doi             = {10.1023/A:1018054314350},
  url             = {https://doi.org/10.1023/A:1018054314350},
  urldate         = {2020-03-24},
  abstract        = {Bagging predictors is a method for generating multiple
                  versions of a predictor and using these to get an aggregated
                  predictor. The aggregation averages over the versions when
                  predicting a numerical outcome and does a plurality vote when
                  predicting a class. The multiple versions are formed by making
                  bootstrap replicates of the learning set and using these as
                  new learning sets. Tests on real and simulated data sets using
                  classification and regression trees and subset selection in
                  linear regression show that bagging can give substantial gains
                  in accuracy. The vital element is the instability of the
                  prediction method. If perturbing the learning set can cause
                  significant changes in the predictor constructed, then bagging
                  can improve accuracy.},
  langid          = {english},
  number          = 2
}

@software{cutlerRandomForestBreimanCutler2018,
  title = {{{randomForest}}: {{Breiman}} and {{Cutler}}'s {{Random Forests}} for {{Classification}} and {{Regression}}},
  shorttitle = {{{randomForest}}},
  author = {Cutler, Fortran original by Leo Breiman {and} Adele and Wiener, R. port by Andy Liaw {and} Matthew},
  date = {2018-03-25},
  url = {https://CRAN.R-project.org/package=randomForest},
  urldate = {2020-03-24},
  abstract = {Classification and regression based on a forest of trees using random inputs, based on Breiman (2001) {$<$}doi:10.1023/A:1010933404324{$>$}.},
  keywords = {Environmetrics,MachineLearning,MissingData},
  version = {4.6-14}
}

@book{cichoszDataMiningAlgorithms2015,
  title           = {Data Mining Algorithms: Explained Using {{R}}},
  shorttitle      = {Data Mining Algorithms},
  author          = {Cichosz, Pawel},
  date            = 2015,
  publisher       = {{John Wiley \& Sons Inc}},
  location        = {{Chichester, West Sussex ; Malden, MA}},
  abstract        = {"This book narrows down the scope of data mining by
                  adopting a heavily modeling-oriented perspective"--},
  isbn            = {978-1-118-95084-5},
  keywords        = {Computer algorithms,Data mining,MATHEMATICS / Probability &
                  Statistics / General,R (Computer program language)},
  pagetotal       = 1
}

@software{galiliDendextendExtendingDendrogram2020,
  title = {Dendextend: {{Extending}} 'dendrogram' {{Functionality}} in {{R}}},
  shorttitle = {Dendextend},
  author = {Galili, Tal and Benjamini, Yoav and Simpson, Gavin, and Gregory, Jefferis and Marco, Gallotta and Renaudie, Johan and Hornik, Kurt and Ligges, Uwe and Spiess, Andrej-Nikolai and Horvath, Steve and Langfelder, Peter, Mark Van Der Loo and Andrie de Vries,and Zuguang Gu and Ma, John and G, Krzysiek and Hummel, Manuela and Clark, Chase and Graybuck, Lucas and jdetribol and Ho, Ben and Perreault, Samuel and Hennig, Christian and Bradley, David},
  date = {2020-02-28},
  url = {https://CRAN.R-project.org/package=dendextend},
  urldate = {2020-03-23},
  abstract = {Offers a set of functions for extending 'dendrogram' objects in R, letting you visualize and compare trees of 'hierarchical clusterings'. You can (1) Adjust a tree's graphical parameters - the color, size, type, etc of its branches, nodes and labels. (2) Visually and statistically compare different 'dendrograms' to one another.},
  keywords = {Cluster,Phylogenetics},
  options = {useprefix=true},
  version = {1.13.4}
}

@book{efronJackknifeBootstrapOther1982,
  title           = {The Jackknife, the Bootstrap, and Other Resampling Plans},
  author          = {Efron, Bradley},
  date            = 1982,
  publisher       = {{Society for Industrial and Applied Mathematics}},
  location        = {{Philadelphia, Pa}},
  isbn            = {978-0-89871-179-0},
  keywords        = {Bootstrap (Statistics),Error analysis
                  (Mathematics),Estimation theory,Jackknife
                  (Statistics),Resampling (Statistics)},
  number          = 38,
  pagetotal       = 92,
  series          = {{{CBMS}}-{{NSF Regional}} Conference Series in Applied
                  Mathematics}
}

@book{hastieElementsStatisticalLearning2009,
  title           = {The Elements of Statistical Learning: Data Mining,
                  Inference, and Prediction},
  shorttitle      = {The Elements of Statistical Learning},
  author          = {Hastie, Trevor and Tibshirani, Robert and Friedman, J. H.},
  date            = 2009,
  edition         = {2nd ed},
  publisher       = {{Springer}},
  location        = {{New York, NY}},
  file            = {/run/media/haozeke/Storage/Zotero/storage/2MQRYYQM/Hastie
                  et al. - 2009 - The elements of statistical learning data
                  mining,.pdf},
  isbn            = {978-0-387-84857-0},
  keywords        = {Bioinformatics,Computational intelligence,Data
                  mining,Forecasting,Inference,Machine
                  learning,Methodology,Statistics},
  note            = 00359,
  pagetotal       = 745,
  series          = {Springer Series in Statistics}
}

@book{jamesIntroductionStatisticalLearning2013,
  title           = {An {{Introduction}} to {{Statistical Learning}}},
  author          = {James, Gareth and Witten, Daniela and Hastie, Trevor and
                  Tibshirani, Robert},
  date            = 2013,
  volume          = 103,
  publisher       = {{Springer New York}},
  location        = {{New York, NY}},
  doi             = {10.1007/978-1-4614-7138-7},
  url             = {http://link.springer.com/10.1007/978-1-4614-7138-7},
  urldate         = {2020-03-19},
  isbn            = {978-1-4614-7138-7},
  langid          = {english},
  series          = {Springer {{Texts}} in {{Statistics}}}
}

@software{kuhnCaretClassificationRegression2020,
  title = {Caret: {{Classification}} and {{Regression Training}}},
  shorttitle = {Caret},
  author = {Kuhn, Max and Wing, Jed and Weston, Steve and Williams, Andre and Keefer, Chris and Engelhardt, Allan and Cooper, Tony and Mayer, Zachary and Kenkel, Brenton and R Core Team and Benesty, Michael and Lescarbeau, Reynald and Ziem, Andrew and Scrucca, Luca and Tang, Yuan and Candan, Can and Hunt, Tyler},
  date = {2020-03-20},
  url = {https://CRAN.R-project.org/package=caret},
  urldate = {2020-03-24},
  abstract = {Misc functions for training and plotting classification and regression models.},
  keywords = {HighPerformanceComputing,MachineLearning,Multivariate},
  version = {6.0-86}
}

@software{langMlr3MachineLearning2020,
  title = {Mlr3: {{Machine Learning}} in {{R}} - {{Next Generation}}},
  shorttitle = {Mlr3},
  author = {Lang, Michel and Bischl, Bernd and Richter, Jakob and Schratz, Patrick and Casalicchio, Giuseppe and Coors, Stefan and Au, Quay and Binder, Martin},
  date = {2020-03-09},
  url = {https://CRAN.R-project.org/package=mlr3},
  urldate = {2020-03-24},
  abstract = {Efficient, object-oriented programming on the building blocks of machine learning. Provides 'R6' objects for tasks, learners, resamplings, and measures. The package is geared towards scalability and larger datasets by supporting parallelization and out-of-memory data-backends like databases. While 'mlr3' focuses on the core computational operations, add-on packages provide additional functionality.},
  keywords = {MachineLearning},
  version = {0.1.8}
}

@software{langRCurlGeneralNetwork2020,
  title = {{{RCurl}}: {{General Network}} ({{HTTP}}/{{FTP}}/...) {{Client Interface}} for {{R}}},
  shorttitle = {{{RCurl}}},
  author = {Lang, Duncan Temple},
  date = {2020-01-19},
  url = {https://CRAN.R-project.org/package=RCurl},
  urldate = {2020-03-21},
  abstract = {A wrapper for 'libcurl' {$<$}http://curl.haxx.se/libcurl/{$>$} Provides functions to allow one to compose general HTTP requests and provides convenient functions to fetch URIs, get \& post forms, etc. and process the results returned by the Web server. This provides a great deal of control over the HTTP/FTP/... connection and the form of the request while providing a higher-level interface than is available just using R socket connections. Additionally, the underlying implementation is robust and extensive, supporting FTP/FTPS/TFTP (uploads and downloads), SSL/HTTPS, telnet, dict, ldap, and also supports cookies, redirects, authentication, etc.},
  keywords = {WebTechnologies},
  version = {1.98-1.1}
}

@article{kassambaraPracticalGuideCluster,
  title           = {Practical {{Guide To Cluster Analysis}} in {{R}}},
  author          = {Kassambara, Alboukadel},
  pages           = 187,
  file            =
                  {/run/media/haozeke/Storage/Zotero/storage/MGHDC7NF/Kassambara
                  - Copyright ©2017 by Alboukadel Kassambara. All righ.pdf},
  langid          = {english}
}

@software{milborrowRpartPlotPlot2019,
  title = {Rpart.Plot: {{Plot}} 'rpart' {{Models}}: {{An Enhanced Version}} of 'Plot.Rpart'},
  shorttitle = {Rpart.Plot},
  author = {Milborrow, Stephen},
  date = {2019-08-22},
  url = {https://CRAN.R-project.org/package=rpart.plot},
  urldate = {2020-03-24},
  abstract = {Plot 'rpart' models. Extends plot.rpart() and text.rpart() in the 'rpart' package.},
  version = {3.0.8}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title           = {Statistical Rethinking: A {{Bayesian}} Course with Examples
                  in {{R}} and {{Stan}}},
  shorttitle      = {Statistical Rethinking},
  author          = {McElreath, Richard},
  date            = 2020,
  edition         = 2,
  publisher       = {{Taylor and Francis, CRC Press}},
  location        = {{Boca Raton}},
  abstract        = {"Statistical Rethinking: A Bayesian Course with Examples in
                  R and Stan, Second Edition builds knowledge/confidence in
                  statistical modeling. Pushes readers to perform step-by-step
                  calculations (usually automated.) Unique, computational
                  approach ensures readers understand details to make reasonable
                  choices and interpretations in their modeling work"--},
  isbn            = {978-0-367-13991-9},
  series          = {{{CRC}} Texts in Statistical Science}
}

@software{therneauRpartRecursivePartitioning2019,
  title = {Rpart: {{Recursive Partitioning}} and {{Regression Trees}}},
  shorttitle = {Rpart},
  author = {Therneau, Terry and Atkinson, Beth and {port}, Brian Ripley (producer of the initial R. and maintainer 1999-2017)},
  date = {2019-04-12},
  url = {https://CRAN.R-project.org/package=rpart},
  urldate = {2020-03-24},
  abstract = {Recursive partitioning for classification, regression and survival trees. An implementation of most of the functionality of the 1984 book by Breiman, Friedman, Olshen and Stone.},
  keywords = {Environmetrics,MachineLearning,Multivariate,Survival},
  options = {useprefix=true},
  version = {4.1-15}
}

@article{mcquittySimilarityAnalysisReciprocal2016,
  title           = {Similarity {{Analysis}} by {{Reciprocal Pairs}} for
                  {{Discrete}} and {{Continuous Data}}:},
  shorttitle      = {Similarity {{Analysis}} by {{Reciprocal Pairs}} for
                  {{Discrete}} and {{Continuous Data}}},
  author          = {McQuitty, Louis L.},
  date            = {2016-07-02},
  journaltitle    = {Educational and Psychological Measurement},
  publisher       = {{Sage PublicationsSage CA: Thousand Oaks, CA}},
  doi             = {10.1177/001316446602600402},
  url             =
                  {https://journals.sagepub.com/doi/10.1177/001316446602600402},
  urldate         = {2020-03-23},
  langid          = {english}
}

@software{wickhamDplyrGrammarData2020,
  title = {Dplyr: {{A Grammar}} of {{Data Manipulation}}},
  shorttitle = {Dplyr},
  author = {Wickham, Hadley and François, Romain and Henry, Lionel and Müller, Kirill and RStudio},
  date = {2020-03-07},
  url = {https://CRAN.R-project.org/package=dplyr},
  urldate = {2020-03-24},
  abstract = {A fast, consistent tool for working with data frame like objects, both in memory and out of memory.},
  keywords = {ModelDeployment},
  version = {0.8.5}
}

@software{wrightRangerFastImplementation2020,
  title = {Ranger: {{A Fast Implementation}} of {{Random Forests}}},
  shorttitle = {Ranger},
  author = {Wright, Marvin N. and Wager, Stefan and Probst, Philipp},
  date = {2020-01-10},
  url = {https://CRAN.R-project.org/package=ranger},
  urldate = {2020-03-24},
  abstract = {A fast implementation of Random Forests, particularly suited for high dimensional data. Ensembles of classification, regression, survival and probability prediction trees are supported. Data from genome-wide association studies can be analyzed efficiently. In addition to data frames, datasets of class 'gwaa.data' (R package 'GenABEL') and 'dgCMatrix' (R package 'Matrix') can be directly analyzed.},
  keywords = {MachineLearning,Survival},
  version = {0.12.1}
}

@article{murtaghWardHierarchicalAgglomerative2014,
  title           = {Ward’s {{Hierarchical Agglomerative Clustering Method}}:
                  {{Which Algorithms Implement Ward}}’s {{Criterion}}?},
  shorttitle      = {Ward’s {{Hierarchical Agglomerative Clustering Method}}},
  author          = {Murtagh, Fionn and Legendre, Pierre},
  date            = {2014-10-01},
  journaltitle    = {Journal of Classification},
  shortjournal    = {J Classif},
  volume          = 31,
  pages           = {274--295},
  issn            = {1432-1343},
  doi             = {10.1007/s00357-014-9161-z},
  url             = {https://doi.org/10.1007/s00357-014-9161-z},
  urldate         = {2020-03-23},
  abstract        = {The Ward error sum of squares hierarchical clustering
                  method has been very widely used since its first description
                  by Ward in a 1963 publication. It has also been generalized in
                  various ways. Two algorithms are found in the literature and
                  software, both announcing that they implement the Ward
                  clustering method. When applied to the same distance matrix,
                  they produce different results. One algorithm preserves Ward’s
                  criterion, the other does not. Our survey work and case
                  studies will be useful for all those involved in developing
                  software for data analysis using Ward’s hierarchical
                  clustering method.},
  langid          = {english},
  number          = 3
}

@article{tibshiraniEstimatingNumberClusters2001,
  title           = {Estimating the Number of Clusters in a Data Set via the Gap
                  Statistic},
  author          = {Tibshirani, Robert and Walther, Guenther and Hastie,
                  Trevor},
  date            = {2001-05},
  journaltitle    = {Journal of the Royal Statistical Society: Series B
                  (Statistical Methodology)},
  shortjournal    = {J Royal Statistical Soc B},
  volume          = 63,
  pages           = {411--423},
  issn            = {1369-7412, 1467-9868},
  doi             = {10.1111/1467-9868.00293},
  url             = {http://doi.wiley.com/10.1111/1467-9868.00293},
  urldate         = {2020-03-23},
  langid          = {english},
  number          = 2
}

@book{zhouEnsembleMethodsFoundations2012,
  title           = {Ensemble {{Methods}}: {{Foundations}} and {{Algorithms}}},
  shorttitle      = {Ensemble {{Methods}}},
  author          = {Zhou, Zhi-Hua},
  date            = {2012-06-06},
  edition         = 0,
  publisher       = {{Chapman and Hall/CRC}},
  doi             = {10.1201/b12207},
  url             = {https://www.taylorfrancis.com/books/9781439830055},
  urldate         = {2020-03-24},
  isbn            = {978-0-429-15109-5},
  langid          = {english}
}

@book{cohencomputer2003,
	title = {Computer {Algebra} and {Symbolic} {Computation}: {Mathematical} {Methods}},
	isbn = {9781568811598},
	shorttitle = {Computer alegebra and symbolic computation II},
	publisher = {A K Peters/CRC Press},
	author = {Cohen, Joel S.},
	year = {2003},
  doi = {10.1201/9781439863701},
	keywords = {Algebra, Data processing},
}

@book{cohencomputer2002,
	title = {Computer {Algebra} and {Symbolic} {Computation}: {Elementary} {Algorithms}},
	isbn = {9780429064753},
	shorttitle = {Computer {Algebra} and {Symbolic} {Computation} I},
	url = {https://www.taylorfrancis.com/books/9781439863695},
	language = {en},
	urldate = {2021-03-25},
	publisher = {A K Peters/CRC Press},
	author = {Cohen, Joel S.},
	month = jul,
	year = {2002},
	doi = {10.1201/9781439863695},
}

@book{redwineUpgradingFortran901995,
  title = {Upgrading to {{Fortran}} 90},
  author = {Redwine, Cooper},
  date = {1995},
  publisher = {{Springer}},
  location = {{New York}},
  annotation = {00016},
  isbn = {978-0-387-97995-3},
  keywords = {FORTRAN 90 (Computer program language)},
  langid = {english},
  pagetotal = {501}
}

@article{theeyancheriTranslationalRotationalDynamics2020,
  title = {Translational and Rotational Dynamics of a Self-Propelled {{Janus}} Probe in Crowded Environments},
  author = {Theeyancheri, Ligesh and Chaki, Subhasish and Samanta, Nairhita and Goswami, Rohit and Chelakkot, Raghunath and Chakrabarti, Rajarshi},
  date = {2020-08-05},
  journaltitle = {Soft Matter},
  shortjournal = {Soft Matter},
  publisher = {{The Royal Society of Chemistry}},
  issn = {1744-6848},
  doi = {10.1039/D0SM00339E},
  url = {https://pubs.rsc.org/en/content/articlelanding/2020/sm/d0sm00339e},
  urldate = {2020-08-05},
  abstract = {We computationally investigate the dynamics of a self-propelled Janus probe in crowded environments. The crowding is caused by the presence of viscoelastic polymers or non- viscoelastic disconnected monomers. Our simulations show that the translational, as well as rotational mean square displacements, have a distinctive three-step growth for fixed values of self-propulsion force, and steadily increase with self-propulsion, irrespective of the nature of the crowder. On the other hand, in the absence of crowders, the rotational dynamics of the Janus probe is independent of self-propulsion force. On replacing the repulsive polymers with sticky ones, translational and rotational mean square displacements of the Janus probe show a sharp drop. Since different faces of a Janus particle interact differently with the environment, we show that the direction of self-propulsion also affects its dynamics. The ratio of long-time translational and rotational diffusivities of the self-propelled probe with a fixed self-propulsion, when plotted against the area fraction of the crowders, passes through a minima and at higher area fraction merges to its value in the absence of the crowder. This points towards the decoupling of translational and rotational dynamics of the self-propelled probe at intermediate area fraction of the crowders. However, such translational-rotational decoupling is absent for passive probes.},
  langid = {english}
}

@book{kayodeFortranProgramsChemical1995,
  title = {Fortran {{Programs}} for {{Chemical Process Design}}, {{Analysis}}, and {{Simulation}}},
  author = {Kayode, A., Coker},
  date = {1995},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-88415-280-4.X5000-6},
  url = {http://linkinghub.elsevier.com/retrieve/pii/B9780884152804X50006},
  urldate = {2018-05-14},
  annotation = {00009},
  isbn = {978-0-88415-280-4},
  langid = {english}
}

@article{goswamiDSEAMSDeferredStructural2020,
  title = {D-{{SEAMS}}: {{Deferred Structural Elucidation Analysis}} for {{Molecular Simulations}}},
  shorttitle = {D-{{SEAMS}}},
  author = {Goswami, Rohit and Goswami, Amrita and Singh, Jayant K.},
  date = {2020-04-27},
  journaltitle = {Journal of Chemical Information and Modeling},
  shortjournal = {J. Chem. Inf. Model.},
  volume = {60},
  pages = {2169--2177},
  publisher = {{American Chemical Society}},
  issn = {1549-9596, 1549-960X},
  doi = {10.1021/acs.jcim.0c00031},
  archiveprefix = {arXiv},
  langid = {english},
  number = {4}
}

@article{wikfeldtTransferableH2OInteraction2013,
  title = {A Transferable {{H2O}} Interaction Potential Based on a Single Center Multipole Expansion: {{SCME}}},
  shorttitle = {A Transferable {{H2O}} Interaction Potential Based on a Single Center Multipole Expansion},
  author = {Wikfeldt, K. T. and Batista, E. R. and Vila, F. D. and Jónsson, H.},
  date = {2013},
  journaltitle = {Physical Chemistry Chemical Physics},
  shortjournal = {Phys. Chem. Chem. Phys.},
  volume = {15},
  pages = {16542},
  issn = {1463-9076, 1463-9084},
  doi = {10/f2z5vm},
  url = {http://xlink.rsc.org/?DOI=c3cp52097h},
  urldate = {2019-11-04},
  abstract = {A transferable potential energy function for describing the interaction between water molecules is presented. The electrostatic interaction is described rigorously using a multipole expansion. Only one expansion center is used per molecule to avoid the introduction of monopoles. This single center approach turns out to converge and give close agreement with ab initio calculations when carried out up to and including the hexadecapole. Both dipole and quadrupole polarizability are included. All parameters in the electrostatic interaction as well as the dispersion interaction are taken from ab initio calculations or experimental measurements of a single water molecule. The repulsive part of the interaction is parametrized to fit ab initio calculations of small water clusters and experimental measurements of ice Ih. The parametrized potential function was then used to simulate liquid water and the results agree well with experiment, even better than simulations using some of the point charge potentials fitted to liquid water. The evaluation of the new interaction potential for condensed phases is fast because point charges are not present and the interaction can, to a good approximation, be truncated at a finite range.},
  annotation = {00000},
  langid = {english},
  number = {39}
}

@article{jonssonPolarizableEmbeddingTransferable2019,
  ids = {jonssonPolarizableEmbeddingTransferable2019a,jonssonPolarizableEmbeddingTransferable2019b},
  title = {Polarizable {{Embedding}} with a {{Transferable H2O Potential Function I}}: {{Formulation}} and {{Tests}} on {{Dimer}}},
  shorttitle = {Polarizable {{Embedding}} with a {{Transferable H2O Potential Function I}}},
  author = {Jónsson, Elvar Örn and Dohn, Asmus Ougaard and Jónsson, Hannes},
  date = {2019-11-05},
  journaltitle = {Journal of Chemical Theory and Computation},
  shortjournal = {J. Chem. Theory Comput.},
  issn = {1549-9618},
  doi = {10.1021/acs.jctc.9b00777},
  url = {https://doi.org/10.1021/acs.jctc.9b00777},
  urldate = {2019-12-09},
  abstract = {The incorporation of mutual polarization in multiscale simulations where different regions of the system are treated at different level of theory is important in studies of, for example, electronic excitations and charge transfer processes. We present here an energy functional for describing a quantum mechanics/molecular mechanics (QM/MM) scheme that includes reciprocal polarization between the two subsystems. The inclusion of polarization alleviates shortcomings inherent in electrostatic embedding QM/MM models based on point-charge force fields. A density functional theory (DFT) description of the QM subsystem is coupled to a single center multipole expansion (SCME) description of H2O molecules in the MM subsystem that includes anisotropic dipole and quadrupole polarizability as well as static multipoles up to and including the hexadecapole. The energy functional and the coupling scheme is general and can be extended to arbitrary order in terms of both the static and induced moments. Tests of the energy surface for the H2O dimer show that the QM/MM results lie in between the pure DFT and pure SCME values. The consistency of the many-body contributions to the energy and analytical forces is demonstrated for an H2O pentamer.},
}

@online{jonssonTransferablePotentialFunction2020,
  title = {Transferable {{Potential Function}} for {{Flexible H}}\$\_2\${{O Molecules Based}} on the {{Single Center Multipole Expansion}}},
  author = {Jónsson, Elvar Örn and Rasti, Soroush and Galynska, Marta and Meyer, Jörg and Jónsson, Hannes},
  date = {2020-07-12},
  url = {http://arxiv.org/abs/2007.06090},
  urldate = {2020-08-03},
  abstract = {A potential function describing a system of flexible water molecules based on a single center multipole expansion of the electrostatic interactions is described, denoted f-SCME. The potential function includes a quadrupole moment surface (QMS) that reproduces results of high level configuration interaction calculations in addition to the commonly used dipole moment surface (DMS) developed by Partridge and Schwenke. The use of the so-called M-site models based on the DMS atomic charges to represent the QMS is explored, and some improvements presented. The potential function also includes the static octupole and hexadecapole moments and anisotropic dipole-dipole, dipole-quadrupole and quadrupole-quadrupole polarizability tensors as well as dispersion interaction of the original rigid SCME potential [SCME, Wikfeldt et al, PCCP 15, 2013 (16542)]. The potential function is parameterized to reproduce the interaction energy of the lowest lying isomer configurations of small water clusters (H\$\_2\$O)\$\_n\$ of \$n=2-6\$, as well as the properties of ice Ih crystal with zero-point energy corrections included. Subsequent calculations of the energy difference between various isomer configurations of the water clusters shows that f-SCME is in good agreement with high level CCSD(T) calculations and represents a significant improvement over the rigid SCME potential function. The f-SCME provides a transferable potential energy function for water molecules applicable to clusters, crystals and liquid configurations.},
  archiveprefix = {arXiv},
  eprint = {2007.06090},
  eprinttype = {arxiv},
  keywords = {Physics - Computational Physics},
  primaryclass = {physics}
}

@thesis{koistinenAlgorithmsFindingSaddle2019,
  title = {Algorithms for {{Finding Saddle Points}} and {{Minimum Energy Paths Using Gaussian Process Regression}}},
  author = {Koistinen, Olli-Pekka},
  date = {2019},
  institution = {{Aalto University School of Science}},
  issn = {1799-4934},
  url = {https://opinvisindi.is/handle/20.500.11815/1460},
  urldate = {2020-03-02},
  abstract = {Chemical reactions and other transitions involving rearrangements of atoms can be studied theoretically by analyzing a potential energy surface defined in a high-dimensional space of atom coordinates. Local minimum points of the energy surface correspond to stable states of the system, and minimum energy paths connecting these states characterize mechanisms of possible transitions. Of particular interest is often the maximum point of the minimum energy path, which is located at a first-order saddle point of the energy surface and can be used to estimate the activation energy and rate of the particular transition.    Minimum energy paths and saddle points between two known states have been traditionally searched with iterative methods where a chain of discrete points of the coordinate space is moved and stretched towards a minimum energy path according to imaginary forces based on gradient vectors of the potential energy surface. The actual saddle point can be found by reversing the component of the gradient vector parallel to the path at one of the points of the chain and letting this point climb along the path towards the saddle point. If the end state of the transition is unknown, the saddle point can be searched correspondingly by rotating a pair of closely spaced points towards the orientation of the lowest curvature, reversing the gradient component corresponding to this direction, and moving the pair towards the saddle point. These methods may, however, require hundreds of iterations, and since accurate evaluation of the gradient vector is often computationally expensive, the information obtained from previous iterations should be utilized as efficiently as possible to decrease the number of iterations. Using statistical models, an approximation to the energy surface can be constructed, and a minimum energy path or a saddle point can be searched on the approximate surface. The accuracy of the solution can be checked with further evaluations, which can be then used to update the model for following iterations.    In this dissertation, machine learning algorithms based on Gaussian process regression are developed to enhance searches of minimum energy paths and saddle points. Gaussian process models serve here as flexible prior probability models for potential energy surfaces. Observed values of both energy and its derivatives can be used to update the model, and the posterior predictive distribution obtained as a result of Bayesian inference provides also an uncertainty estimate, which can be utilized when selecting new observation points. Separate methods are presented both for finding a minimum energy path between two known states and a saddle point located in the vicinity of a given start point. Based on simple test examples, the methods utilizing Gaussian processes may reduce the number of evaluations to a fraction of what is required by conventional methods.},
  annotation = {Accepted: 2020-01-24T11:21:17Z},
  keywords = {archived},
  langid = {english}
}

@article{koistinenMinimumModeSaddle2020,
  title = {Minimum {{Mode Saddle Point Searches Using Gaussian Process Regression}} with {{Inverse}}-{{Distance Covariance Function}}},
  author = {Koistinen, Olli-Pekka and Ásgeirsson, Vilhjálmur and Vehtari, Aki and Jónsson, Hannes},
  date = {2020-01-14},
  journaltitle = {Journal of Chemical Theory and Computation},
  shortjournal = {J. Chem. Theory Comput.},
  volume = {16},
  pages = {499--509},
  publisher = {{American Chemical Society; http://web.archive.org/web/20200511135845/https://pubs.acs.org/doi/10.1021/acs.jctc.9b01038}},
  issn = {1549-9618},
  doi = {10.1021/acs.jctc.9b01038},
  url = {10.1021/acs.jctc.9b01038},
  urldate = {2020-05-11},
  abstract = {The minimum mode following method can be used to find saddle points on an energy surface by following a direction guided by the lowest curvature mode. Such calculations are often started close to a minimum on the energy surface to find out which transitions can occur from an initial state of the system, but it is also common to start from the vicinity of a first-order saddle point making use of an initial guess based on intuition or more approximate calculations. In systems where accurate evaluations of the energy and its gradient are computationally intensive, it is important to exploit the information of the previous evaluations to enhance the performance. Here, we show that the number of evaluations required for convergence to the saddle point can be significantly reduced by making use of an approximate energy surface obtained by a Gaussian process model based on inverse interatomic distances, evaluating accurate energy and gradient at the saddle point of the approximate surface and then correcting the model based on the new information. The performance of the method is tested with start points chosen randomly in the vicinity of saddle points for dissociative adsorption of an H2 molecule on the Cu(110) surface and three gas phase chemical reactions.},
  number = {1}
}

@article{koistinenNudgedElasticBand2017,
  title = {Nudged Elastic Band Calculations Accelerated with {{Gaussian}} Process Regression},
  author = {Koistinen, Olli-Pekka and Dagbjartsdóttir, Freyja B. and Ásgeirsson, Vilhjálmur and Vehtari, Aki and Jónsson, Hannes},
  date = {2017-09-21},
  journaltitle = {The Journal of Chemical Physics},
  shortjournal = {J. Chem. Phys.},
  volume = {147},
  pages = {152720},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/1.4986787},
  url = {https://aip.scitation.org/doi/full/10.1063/1.4986787},
  urldate = {2020-03-02},
  number = {15}
}

@article{koistinenNudgedElasticBand2019,
  title = {Nudged {{Elastic Band Calculations Accelerated}} with {{Gaussian Process Regression Based}} on {{Inverse Interatomic Distances}}},
  author = {Koistinen, Olli-Pekka and Ásgeirsson, Vilhjálmur and Vehtari, Aki and Jónsson, Hannes},
  date = {2019-12-10},
  journaltitle = {Journal of Chemical Theory and Computation},
  shortjournal = {J. Chem. Theory Comput.},
  volume = {15},
  pages = {6738--6751},
  publisher = {{American Chemical Society}},
  issn = {1549-9618},
  doi = {10.1021/acs.jctc.9b00692},
  url = {https://doi.org/10.1021/acs.jctc.9b00692},
  urldate = {2020-03-02},
  abstract = {Calculations of minimum energy paths for atomic rearrangements using the nudged elastic band method can be accelerated with Gaussian process regression to reduce the number of energy and atomic force evaluations needed for convergence. Problems can arise, however, when configurations with large forces due to short distance between atoms are included in the data set. Here, a significant improvement to the Gaussian process regression approach is obtained by basing the difference measure between two atomic configurations in the covariance function on the inverted interatomic distances and by adding a new early stopping criterion for the path relaxation phase. This greatly improves the performance of the method in two applications where the original formulation does not work well: a dissociative adsorption of an H2 molecule on a Cu(110) surface and a diffusion hop of an H2O molecule on an ice Ih(0001) surface. Also, the revised method works better in the previously analyzed benchmark application to rearrangement transitions of a heptamer island on a surface, requiring fewer energy and force evaluations for convergence to the minimum energy path.},
  number = {12}
}

@article{chillEONSoftwareLong2014,
  title = {{{EON}}: Software for Long Time Simulations of Atomic Scale Systems},
  shorttitle = {{{EON}}},
  author = {Chill, Samuel T and Welborn, Matthew and Terrell, Rye and Zhang, Liang and Berthet, Jean-Claude and Pedersen, Andreas and Jónsson, Hannes and Henkelman, Graeme},
  date = {2014-07-01},
  journaltitle = {Modelling and Simulation in Materials Science and Engineering},
  shortjournal = {Modelling Simul. Mater. Sci. Eng.},
  volume = {22},
  pages = {055002},
  issn = {0965-0393, 1361-651X},
  doi = {10.1088/0965-0393/22/5/055002},
  url = {http://stacks.iop.org/0965-0393/22/i=5/a=055002?key=crossref.261e995bd522c17721544389499d4ef1},
  urldate = {2019-07-06},
  annotation = {00000},
  langid = {english},
  number = {5}
}
