#+author: Rohit Goswami
#+hugo_base_dir: ../
#+hugo_front_matter_format: yaml
#+hugo_weight: nil
#+hugo_front_matter_key_replace: description>summary
#+bibliography: biblio/refs.bib

#+seq_todo: TODO DRAFT DONE
#+seq_todo: TEST__TODO | TEST__DONE

#+property: header-args :eval never-export

#+startup: logdone indent overview inlineimages

#+hugo_section: ./snippets

* Snippets
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:END:
This collection consists of a series of snippets which are not particularly long enough or interesting enough to be a post. However, they are frequently used by me, and thus deserve a spot somewhere.
* Code :@code:
** DONE Overwriting Attributes :nix:
CLOSED: [2021-05-16 Sun 03:47]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: nix-collection-overwrite-attrs
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:
#+begin_src nix
  doxygen191 = pkgs.doxygen.overrideAttrs (_: rec {
  name = "doxygen-1.9.1";
  src = pkgs.fetchurl {
    urls = [
      "mirror://sourceforge/doxygen/${name}.src.tar.gz" # faster, with https, etc.
      "http://doxygen.nl/files/${name}.src.tar.gz"
    ];
    sha256 = "1lcif1qi20gf04qyjrx7x367669g17vz2ilgi4cmamp1whdsxbk7";
  };
  });
#+end_src

** DONE Forwarding Multiple Local Ports :ssh:
CLOSED: [2021-05-16 Sun 03:47]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: forward-multiport
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:
Most often it makes more sense to map the same ports on every intermediate machine.
#+begin_src conf
Host super
  Hostname super.machine.location.is
  IdentityFile ~/.ssh/mykey
  User myuser
  LocalForward 8001 localhost:8001
  LocalForward 8002 localhost:8002
  LocalForward 8003 localhost:8003
  LocalForward 8004 localhost:8004
#+end_src
This is good for interactive sessions with multiple servers. For single servers, reverse proxy tunnels are more efficient.
** DONE Programming Language Management :shell:lang:
CLOSED: [2021-09-19 Sun 17:39]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: prog-lang-man
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:
~nix~ aside[fn:whynot], I recently shifted to using [[https://asdf-vm.com/guide/getting-started.html#_3-install-asdf][asdf]] to manage different language versions.
#+begin_src bash
git clone https://github.com/asdf-vm/asdf.git ~/.asdf --branch v0.8.1
#+end_src
The main reason to prefer ~asdf~ over competing language specific options like ~rvm~ or ~pyenv~ or ~nvm~ and company is simply uniformity of the interface. This can be coupled with ~zinit snippet OMZ::plugins/asdf~ for loading the completions. Note that the installation steps can take a while especially if ~openssl~ is being installed.
*** Configuration
Actually one weird aspect of ~asdf~ is that it pollutes ~$HOME~ by default
instead of respectfully storing its configuration in ~$HOME/.config/asdf~ like
every other program. To change this; exporting ~ASDF_CONFIG_FILE~ works.
Essentially a ~zsh~ configuration with ~zinit~ would look like this[fn:whatwhy]:
#+begin_src bash
if [[ ! -d ~/.asdf ]]; then
    mkdir ~/.asdf
    git clone https://github.com/asdf-vm/asdf.git ~/.asdf
fi

export ASDF_CONFIG_FILE="~/.config/asdf/asdfrc"
zinit snippet OMZ::plugins/asdf
#+end_src

~asdf~ has an option; ~legacy_version_file = yes~ which is meant to ensure that
existing solutions (e.g. ~.nvmrc~ or ~.node-version~) are compatible. There is
also ~$HOME/.tool-versions~ for trickle-down language versions; that is
language-version pairs defined in such files are activated for the directory and
lower sub-directories. The rest of a reasonable configuration ([[https://asdf-vm.com/manage/configuration.html][described here]])
might look like:
#+begin_src bash
legacy_version_file = yes
always_keep_download = no
#+end_src
*** Ruby
This [[https://github.com/asdf-vm/asdf-ruby][plugin]] leverages [[https://github.com/rbenv/ruby-build#custom-build-configuration][ruby-build]] and so can take a pick up an extended set of
environment variables; it supports ~.ruby-version~ files as well.
#+begin_src bash
asdf plugin add ruby
asdf list all ruby
asdf install ruby 3.0.2
asdf global ruby 3.0.2 # Convenience
#+end_src
*** NodeJS
This [[https://github.com/asdf-vm/asdf-nodejs][plugin]] respects ~.nvmrc~ and ~.node-version~ files.
#+begin_src bash
asdf plugin add nodejs
asdf global nodejs latest
asdf install nodejs latest
#+end_src
*** Python
Builds with [[https://github.com/yyuu/pyenv/tree/master/plugins/python-build][python-build]].
#+begin_src bash
asdf plugin add python
asdf install python 3.9.7
asdf global python 3.9.7
#+end_src
*** Direnv
I'm a huge fan of ~direnv~; and a [[https://github.com/asdf-community/asdf-direnv][fantastic little plugin]] (with neat ~hyperfine~ benchmarks) for ~asdf~ removes a layer of shim indirection while playing nicely with ~direnv~.
#+begin_src bash
asdf plugin-add direnv
asdf install direnv latest
asdf global direnv latest
#+end_src
This comes with an associated set of shell profile instructions:
#+begin_src bash
# File: ~/.zshrc
# Hook direnv into your shell.
eval "$(asdf exec direnv hook zsh)"
# A shortcut for asdf managed direnv.
direnv() { asdf exec direnv "$@"; }
#+end_src
Along with a commiserate ~$HOME/.config/direnv/direnvrc~ requirement:
#+begin_src bash
source "$(asdf direnv hook asdf)"
#+end_src
Now every new ~.envrc~ can start with ~use asdf~ which will now speed up evaluations.
*** Conclusions
This method appears to be more robust than remembering the various idiosyncrasies and logic of a host of other tools.

[fn:whatwhy] This structure can be seen in [[https://github.com/HaoZeke/Dotfiles][my own Dotfiles]] as well
[fn:whynot] This was during the [[https://github.com/Ericson2314/nix-rfcs/blob/plan-dynamism/rfcs/0000-plan-dynanism.md][build plan dynamism RFCs]] which themselves were symptomatic of the ~{yarn,composer,node,*}2nix~ issues
** DONE Watching Files :productivity:cmdline:ruby:rust:
CLOSED: [2021-09-19 Sun 17:39]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: watch-files
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:
My personal favorite for watching files and running context sensitive commands is to use the lovely [[https://github.com/filewatcher/filewatcher][filewatcher CLI utility]] written in Ruby.
#+begin_src bash
gem install filewatcher
gem install filewatcher-cli
#+end_src
This can then be used with:
#+begin_src bash
filewatcher '**/*.js' 'node $FILENAME'
#+end_src
However this hasn't been updated in a while now *and fails* on newer versions of Ruby. So now I use [[https://github.com/watchexec/watchexec/tree/main/cli#installation][watchexec]].
#+begin_src bash
cargo install watchexec-cli
watchexec -w source/f2py 'make html'
#+end_src
** DONE Docker Development Environments :devenv:cmdline:
CLOSED: [2021-11-24 Wed 16:20]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: docker-dev-envs
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:
Very quick set of ugly commands to grab build environments. A much better
approach is to make a custom Dockerfile or even better, use ~nix~.

However it does work in a pinch.
#+begin_src bash
docker pull IMG:TAG
sudo docker run -v LOCALDIR:DIRINDOCKER -it debian:experimental-20211115 bash
# Don't be root for long
apt update
apt install sudo vim zsh
# Use the same username --> easier to manage permissions
useradd -m -s /bin/zsh $USER -G sudo
passwd $USER # Some crap
# Or just add to the sudoers file
echo "$USER ALL=(ALL:ALL) ALL" >> /etc/sudoers
su $USER
# numpy stuff
sudo apt install gcc gfortran libopenblas-dev python3.10-dev python3.10-dbg git python3-distutils python3-setuptools libx11-dev build-essential pkg-config python3-pip python3-pytest python3-hypothesis
python3.10-dbg runtests.py -s f2py -vvv
#+end_src
** DONE SSH Port Forwarding :ssh:
CLOSED: [2021-11-24 Wed 16:20]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: ssh-port-forwarding
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:
Whenever I need to access a server running on an HPC which does not support ~ngrok~ or ~localtunnel~ or even ~gsocket~; the fallback approach is always to rely on SSH port forwarding.

The sample problem here is running an HTTP server for viewing graphics in R via ~httpgd~.
#+begin_src bash
# Local
export PORT=9899 && ssh -L "${PORT}:localhost:${PORT}" "rog32@krafla.rhi.hi.is" -N -L "${PORT}:localhost:${PORT}" elja
# New tab
ssh krafla
ssh elja
radian # or R
#+end_src
Now in ~R~.
#+begin_src R
library("httpgd")
# else install.packages(c("httpgd"), repos='https://cran.hafro.is/')
hgd(port=9899)
#+end_src
*** Conda and R
Annoyingly if you are depending on ~conda~ or ~micromamba~ or some variant thereof on the remote sever then ~install.packages~ will fail and instead the environment needs to have the corresponding ~R~ packages installed after searching [[https://anaconda.org/][anaconda.org]].
#+begin_src bash
# minimal
micromamba create -p $(pwd)/.tmp -c conda-forge r-tidyverse  git R
micromamba activate $(pwd)/.tmp
micromamba install -c nclibz r-httpgd
#+end_src

These issues are not present when using a ~nix-shell~.
** DONE Mach-Nix and Shell Environments :nix:python:cmdline:
CLOSED: [2022-01-17 Mon 02:28]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: mach-nix-shell-env
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:
I often need to set up quick virtual environments. Unfortunately, the standard
approach to work with this in ~nix~ deals with the local ~nixpkgs~ mechanism for
~python~ dependencies:
#+begin_src bash
nix-shell -p "python38.withPackages(ps: [ ps.numpy ps.sh ])"
#+end_src
However there is a catch for packages which are not officially present upstream.
#+begin_src bash
# Fails!
nix-shell -p "python38.withPackages(ps: [ ps.numpy ps.sh ps.lieer ])"
#+end_src
However, the ~mach-nix~ project can indeed be used to work around this, at the
cost of a somewhat longer command.
#+begin_src bash
# Works
nix-shell -p '(callPackage (fetchTarball https://github.com/DavHau/mach-nix/tarball/3.0.2) {python="python38";}).mkPython{requirements="numpy\n lieer\n ipython";}' --command ipython
#+end_src
~mkPythonShell~ does not generate an environment which can be used here, since
that is not a derivation which can be built.  This is most useful in the context
of systems which use ~asdf~ or other ~PATH~ shim approaches.
** DONE Auto-discovering ~meson~ tests :meson:cpp:build:
CLOSED: [2023-03-22 Wed 13:59]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: auto-disc-meson-tests
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:

One of the things I missed when I migrated from ~cmake~ to ~meson~ was the ease
at which ~cmake~ discovers tests.

#+begin_src cmake
# Tests
option(PACKAGE_TESTS "Build the tests" OFF)
if(PACKAGE_TESTS)
  find_package(GTest REQUIRED)
  enable_testing()
  include(GoogleTest)
  add_subdirectory(gtests)
endif()
#+end_src

Thankfully, ~meson~ can kind of emulate this behavior, even in its restricted
syntax. The key concept is **arrays** and their iterators.

#+begin_src meson
test_array = [#
  # ['Pretty name', 'binary_name', 'BlahTest.cpp']
  ['String parser helpers', 'strparse_run', 'StringHelpersTest.cpp'],
  ['Improved Dimer', 'impldim_run', 'ImpDimerTest.cpp'],
]
foreach test : test_array
  test(test.get(0),
       executable(test.get(1),
          sources : ['gtests/'+test.get(2)],
          dependencies : [ prog_deps, gtest_dep, gmock_dep ],
          link_with : proglib,
          cpp_args : prog_extra_args
                 ),
      )
endforeach
#+end_src

Now this is pretty neat already, but we can go a step further and augment this
with a working directory concept.

#+begin_src meson
test_array = [#
  # ['Pretty name', 'binary_name', 'BlahTest.cpp', 'working_dir']
  ['Improved Dimer', 'impldim_run', 'ImpDimerTest.cpp', '/gtests/data/'],
  ['Matter converter', 'matter_run', 'MatterTest.cpp', '/gtests/data/systems/sulfolene'],
  ['String parser helpers', 'strparse_run', 'StringHelpersTest.cpp', ''],
]
foreach test : test_array
  test(test.get(0),
       executable(test.get(1),
          sources : ['gtests/'+test.get(2)],
          dependencies : [ prog_deps, gtest_dep, gmock_dep ],
          link_with : proglib,
          cpp_args : prog_extra_args
                 ),
        workdir : meson.source_root() + test.get(3)
      )
endforeach
#+end_src

This is rather satisfying. Combined with some ~wraps~, it is also pretty
portable.

** DONE Zotero Connector and Blog Posts
CLOSED: [2023-08-23 Wed 00:17]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: zotero-connector-blog-posts
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:
It so happens that *only* a precious few generators are recognized for parsing blog-post entries into Zotero, that is:
#+begin_src html
<meta name=generator content="Wordpress">
<!-- or  -->
<meta name=generator content="Blogger">
<!-- or  -->
<meta name=generator content="Wooframework">
#+end_src
This is really rather silly to put on say, a ~hugo~ generated site, but since
the embedded metadata-parsing is so much better, it kind of makes sense to do so
as a stop gap solution.

The code which handles these ~meta~ tags for ~blogPosts~ can be [[https://github.com/zotero/translators/blob/b6eb8802779a538752435f567a6c1461d87cdfac/Embedded%20Metadata.js#L306-L313][seen upstream]].
Will be fixed by [[https://github.com/zotero/translators/pull/3116][this PR]] soon enough hopefully.
** TODO Github Action Blocks
Concurrency is a great idea.
** TODO Applying Patches Across Repositories :git:cmdline:patch:
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: git-commit-patch
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:
Consider a situation where one has inadvertently ripped out the guts of an
existing ~python~ project, and decided to update it and recursively apply said
updates upstream.
#+begin_quote
What?
#+end_quote
OK. Skip to the example.

#+begin_src bash
git log
# Grab commit hash, $SHA
git format-patch -1 $SHA
# Outputs a cute filename.patch, we'll call it $FNAME
#+end_src

Now we can go to where we need to apply said patch and..

#+begin_src bash
patch -p1 < $FNAME
#+end_src

Which assumes that the leading directories are the same. Variants of this are:
#+begin_src bash
# For a range
git format-patch $SHA1~1..$SHA2
# For use in a git tree
git apply --check $FNAME # dry-run
git apply $FNAME # prod
#+end_src

*** Example
For a concrete example, consider migrating refactored tests from a submodule into an upstream repository.

** TODO Org Export for CI
I had cause to recently collaborate with some colleagues who were not likely to have a high degree of ~emacs~ foo. Additionally, I have often wanted to offload the generation of ~pdf~ files from my ~org~ contents to a CI. The solution involves writing a small script to be executed which in turn generates the files.
** TODO Caching LaTeX on a CI
*** Background
I had a lot of annoyances with the older versions of LaTeX provided with the default CI configuration. Additionally, there was sub optimal caching of the packages used. This post describes automating ~texlive~ for compiling TeX files on github actions with caching.
#+begin_src bash
tlmgr search --global --file asana
#+end_src
** TODO Mamba and Colab :ssh:colab:python:
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: mamba-colab-usage
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc false :comments true
:END:
I am not particularly fond on web based programming workflows. They feel ephemeral to my dated sensibilities. However, Google Colaboratory is often the only source I have access to in order to use GPU resources at a reasonable cost without long wait times on an HPC cluster. Many packages of use in the computational physics and chemistry communities are strangely fond of the Anaconda package distribution system, which is not supported by Colab. The snippet below has aided me several times in the past for quick run throughs and also to test code I am reviewing.

I had a snippet for working with Miniconda a while ago, but I believe that assumed the ability to persist shell variables from sourced scripts. In any case, I prefer working with ~micromamba~ now.

#+begin_src bash
%%bash
wget -qO- https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba
#+end_src

Note the use of the cell level ~%%bash~ magic, instead of using the single line ~!~ escape, it is not a great idea to mix languages in one cell for posterity.

Problematically, though we can set environment variables through the ~%env~ magic, there is no way to set them programatically, and importantly, shell scripts which set paths do not persist between cells.

Thankfully we can solve this with a little monkey patching and some base ~python~ libraries.

#+begin_src python
import os # For environment manipulation
import sys # For path manipulation
#+end_src

Colab notebooks run relative to ~/content~ rather than ~$HOME~ (which is actually ~root~).

Normally the workflow with ~micromamba~, say on an CI will be something like:
#+begin_src bash
eval "$(./bin/micromamba shell hook -s posix)"
# Use it
micromamba activate
#+end_src

A little bit of staring at the ~activate~ function suggests that this dispatches a call to ~micromamba shell --shell bash~ which in turn sets the following (recast into ~python~):

#+begin_src python
%env MAMBA_ROOT_PREFIX=/content/mmb
os.environ['PATH'] = ":/content/mmb/bin:/content/mmb/condabin:/content/bin/:"+os.environ['PATH']
os.environ['CONDA_PREFIX'] = "/content/mmb"
os.environ['CONDA_SHLVL'] = '1'
os.environ['CONDA_DEFAULT_ENV'] = 'base'
os.environ['CONDA_PROMPT_MODIFIER'] = 'base'
#+end_src

Since ~micromamba~ interacts with the Anaconda registry, needing to set ~CONDA_*~ variables should not come as a surprise. ~PS1~ is also modified, but this would be pointless on Colab.

Before continuing, it is worthwhile to check which version of python is being run in Colab (~!python --version~). As of this post, Colab uses ~python 3.7~, so we will use the same.

For my example, I am interested in trying out ~lfortran~.
#+begin_src bash
%%bash
micromamba install python=3.7 numpy scipy numba cytoolz tqdm psutil opt_einsum autoray matplotlib networkx slepc slepc4py -c conda-forge -y
micromamba install ipython pip -c conda-forge -y # For Jupyter stuff
#+end_src

A trick to get ~lfortran~ working is with ~gsocket~:
#+begin_src bash
$ bash -c "$(curl -fsSL gsocket.io/x)"
#+end_src

Now on a local machine:
#+begin_src bash
S="something" bash -c "$(wget -qO- gsocket.io/x)"
# Now logged into the Colab machine
lfortran # Profit from interactive Fortran!
#+end_src
** TODO Nix Shell and Locales
From [[https://github.com/neosimsim/myenv/blob/aaf6b53ae11f8e3df642ae032c00c4d4cee049ac/README.md][here]]. Often ~nix-shell~ invocations have the following issue:
#+begin_src bash
bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
#+end_src
The fix is in two parts:
#+begin_src bash
# Install glibc
nix-env -i glibc-locales
#+end_src
Then use it in the ~shellHook~ as:
#+begin_src nix
  shellHook = ''
    # Locale
    export LOCALE_ARCHIVE=${pkgs.glibcLocales}/lib/locale/locale-archive
  '';
#+end_src
Or directly as ~export LOCALE_ARCHIVE="$(nix-env --installed --no-name --out-path --query glibc-locales)/lib/locale/locale-archive"~
** TODO Nix Thoughts
** TODO On Hyread and Color E-Ink
*** ~adb~ rules
A quick glance at the output of ~lsusb~ yields:
#+begin_src bash
Bus 003 Device 004: ID 04f2:b751 Chicony Electronics Co., Ltd Integrated Camera
#+end_src

Which suggests the following rule:
#+begin_src bash
cat /etc/udev/rules.d/51-android.rules
SUBSYSTEM=="usb", ATTR{idVendor}=="04f2", MODE="0660", GROUP="adbusers", TAG+="uaccess"
SUBSYSTEM=="usb", ATTR{idVendor}=="04f2", ATTR{idProduct}=="b751", SYMLINK+="android_adb"
SUBSYSTEM=="usb", ATTR{idVendor}=="04f2", ATTR{idProduct}=="b751", SYMLINK+="android_fastboot"
#+end_src

With these forcibly loaded via ~sudo udevadm trigger~, the device should show up
with ~adb devices~.
** TODO Overrides and Nix
I recently had to extend my ~nix~ installed ~git~ version to get ~git-svn~ and to upgrade to the latest version. This was fairly straightforward.
#+begin_src nix
  myGit = (pkgs.git.overrideAttrs (o: rec {
    version = "2.32.0";
    doInstallCheck = false;
    src = pkgs.fetchurl {
      url = "https://www.kernel.org/pub/software/scm/git/git-${version}.tar.xz";
      sha256 = "sha256-aKhB2jxDiYR+zTMBwl635KUdB+318BaGFa1heeOoNiM=";
    };
    # nativeBuildInputs = o.nativeBuildInputs ++ [pkgs.stdenv];
  })).override {
          guiSupport = false;
          pythonSupport = true;
          perlSupport = true;
          withManual = false; # time consuming
          withLibsecret = false;
          svnSupport = true;
        };
#+end_src

