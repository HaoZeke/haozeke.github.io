<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>programming on Rohit Goswami</title><link>/categories/programming/</link><description>Recent content in programming on Rohit Goswami</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0&lt;/a>.</copyright><lastBuildDate>Wed, 21 Jul 2021 02:01:00 +0000</lastBuildDate><atom:link href="/categories/programming/index.xml" rel="self" type="application/rss+xml"/><item><title>Nix, Channels and the NUR</title><link>/posts/nix-channel-nur/</link><pubDate>Wed, 21 Jul 2021 02:01:00 +0000</pubDate><guid>/posts/nix-channel-nur/</guid><description>A short exploration of multi-user nix and interacting with the Nix User Repository without root
Background For multi-user nix installations 1, the NIX_PATH variable is empty. Here I briefly go over two approaches to mitigate this, one with nix-channel and the other by manual pinning. Note that this post will eventually be superseded for most cases by a better flake workflow.
Channels The idea behind using a channel is essentially that the tar at a particular commit / tag will be downloaded and stored, typically at $HOME/.</description></item><item><title>Doom Emacs and Language Servers</title><link>/posts/emacs-lang-servers/</link><pubDate>Tue, 20 Jul 2021 02:28:00 +0000</pubDate><guid>/posts/emacs-lang-servers/</guid><description>doom-emacs as an ssh IDE with TRAMP using eglot and language servers.
Background For most of my emacs configuration1, there normally isn&amp;rsquo;t very much to write about which isn&amp;rsquo;t immediately evident from my configuration site. However, since my shift to a MacBook, I have needed to fine tune my existing lsp-mode default setup for TRAMP and this post will cover a little bit of that. Though most of the post is about doom-emacs, it is also applicable to vanilla emacs after porting the snippets over to use-package instead.</description></item><item><title>HPC Configuration 2021</title><link>/posts/hpc-conf-2021/</link><pubDate>Sun, 09 May 2021 23:12:00 +0000</pubDate><guid>/posts/hpc-conf-2021/</guid><description>A post on configuring a user account for heavy interactive HPC usage with Spack, Nix and self-hosted applications.
Background I have in the past written a few posts about configuring my HPC setup. Since the Research and University Network of Iceland hf. (RHnet) recently recieved funding for a new machine, called Elja 1, I decided to jot down my notes from my setup as part of the user interaction team.</description></item><item><title>Project Specific Expressions from Nixpkgs for Sphinx documentation</title><link>/posts/nix-prj-spec-doc/</link><pubDate>Tue, 22 Dec 2020 05:09:00 +0000</pubDate><guid>/posts/nix-prj-spec-doc/</guid><description>Short post on making minimal changes to derivations in nixpkgs at a project level using callPackage() along with GH-Actions for deployment of sphinx documentation.
Background As part of my work on the Symengine documentation1, I had originally thought of leveraging nix for reproducible builds for each of the language bindings with GH-Actions. There exists a derivation in the upstream package repository, but it was outdated (v6.0.0 instead of v6.0.1) 2.</description></item><item><title>Anki Decks with Orgmode</title><link>/posts/anki-decks-orgmode/</link><pubDate>Tue, 27 Oct 2020 01:05:00 +0000</pubDate><guid>/posts/anki-decks-orgmode/</guid><description>Setting up unicode math and orgmode for painless Anki deck building
Background A recent Hacker News post reminded me of Anki, and that brought back memories of my Anki orgmode setup. I thought I&amp;rsquo;d re-create and immortalize it.
The standard way of working with Anki, is with a pretty awkward GUI. There are changes to be made here, which make life a little easier, including the setup of custom cards, but the inherent concerns of the WYSIWYG editor are basically insurmountable.</description></item><item><title>Publishing Doxygen and Sphinx with Nix and Rake</title><link>/posts/pub-doc-cpp-dox-sph-nix/</link><pubDate>Tue, 22 Sep 2020 10:30:00 +0000</pubDate><guid>/posts/pub-doc-cpp-dox-sph-nix/</guid><description>Automating documenation deployment with Travis, rake and nix
Background In the previous post we generated documentation using Doxygen with Exhale to handle Sphinx. Now we will clean up the earlier workflow with rake and ensure the environment is reproducible with nix while deploying to Travis CI.
Series Documenting C++ with Doxygen and Sphinx - Exhale Publishing Doxygen and Sphinx with Nix and Rake &amp;lt;&amp;ndash; You are here Documenting C++ with Doxygen and Sphinx - doxyrest Adding Tutorials to Sphinx Projects Setup A quick reminder of the setup we generated in the last post:</description></item><item><title>Documenting C++ with Doxygen and Sphinx - Exhale</title><link>/posts/doc-cpp-dox-sph-exhale/</link><pubDate>Tue, 22 Sep 2020 06:58:00 +0000</pubDate><guid>/posts/doc-cpp-dox-sph-exhale/</guid><description>This post outlines a basic workflow for C++ projects using Doxygen, Sphinx, and Exhale.
Background My project proposal for documenting Symengine was recently accepted for the Google Summer of Docs initiative. In the past I have been more than happy to document C++ code using only Doxygen (with pretty fantastic results), while keeping example usage separate (d-SEAMS wiki). Though this is still a feasible method, a monolithic multi-project setup might benefit from Sphinx, which is what will be covered.</description></item><item><title>Local Nix without Root</title><link>/posts/local-nix-no-root/</link><pubDate>Mon, 07 Sep 2020 18:30:00 +0000</pubDate><guid>/posts/local-nix-no-root/</guid><description>Monkeying around with nix for HPC systems which have no root access and NFS filesystems.
Background Nix is not well known for being friendly to users without root access. This is typically made worse by the &amp;ldquo;exotic&amp;rdquo; filesystem attributes common to HPC networks (this also plagues hermes). An earlier post details how and why proot failed. The short pitch is simply:
Figure 1: Does your HPC look like this?</description></item><item><title>Niv and Mach-Nix for Nix Python</title><link>/posts/mach-nix-niv-python/</link><pubDate>Wed, 26 Aug 2020 05:42:00 +0000</pubDate><guid>/posts/mach-nix-niv-python/</guid><description>Short post on using mach-nix with niv.
Background In previous posts, there was a discussion on a ground up approach to adding packages which aren&amp;rsquo;t on the core nixpkgs channels using GitHub or PyPi sources. However, this lacked a way to do so programmatically, and also a way to convert existing python projects.
Python Dependency Management This time, instead of the more pedagogical approach of building packages from PyPi or GitHub, we will use overlays and the excellent mach-nix to speed up the process.</description></item><item><title>Nix Shells for Node Projects</title><link>/posts/nix-shell-node/</link><pubDate>Sun, 23 Aug 2020 10:09:00 +0000</pubDate><guid>/posts/nix-shell-node/</guid><description>Background As a prelude to writing up the details of how this site is generated, I realized I should write up a nix oriented workflow for node packages.
Tooling and Idea The basic concepts are:
Use npm to generate a package-lock.json file Use node2nix in a shell to generate a set of nix derivations Enter a shell environment with the nix inputs Profit However, the nuances of this are a bit annoying at first.</description></item><item><title>A Tutorial Introduction to Nix</title><link>/posts/ccon-tut-nix/</link><pubDate>Tue, 18 Aug 2020 16:18:00 +0000</pubDate><guid>/posts/ccon-tut-nix/</guid><description>Brief introduction to a nix based project workflow.
Background For CarpentryCon@Home 2020, along with Amrita Goswami, I am to prepare and deliver a workshop on &amp;ldquo;Reproducible Environments with the Nix Packaging System&amp;rdquo;. In particular, as a community of practice lesson, the focus is not on packaging (as is typical of most Nix tutorials) nor on the Nix expression language itself, but instead on the use of Nix as a replacement for virtual environments using mkShell.</description></item><item><title>HPC Dotfiles and LMod</title><link>/posts/hpc-dots-lmod/</link><pubDate>Sun, 09 Aug 2020 02:29:00 +0000</pubDate><guid>/posts/hpc-dots-lmod/</guid><description>Background My move away from the powerful, but unimaginatively named HPC clusters of IITK 1 brought me in close contact with the Lua based 2 lmod module system. Rather than fall into the rabbit hole of brew we will leverage the existing system to add our new libraries. Not finding any good collections of these composable environments, and having failed once before to install Nix as a user without admin access, I decided to start my own collection of Lmod recipies.</description></item><item><title>A Short Guide to Statistical Rethinking²</title><link>/posts/some-sol-sr2/</link><pubDate>Fri, 24 Jul 2020 17:35:00 +0000</pubDate><guid>/posts/some-sol-sr2/</guid><description>A meta post introducing my solutions to the fantastic excellent second edition of &amp;ldquo;Statistical Rethinking&amp;rdquo; by Richard McElreath, a.k.a. Statistical Rethinking². Also discusses strategies to keep up with the material, mostly meant for self-study groups.
Background As detailed previously, I recently was part of a course centered around Bayesian modeling for the Icelandic COVID-19 pandemic. The Bayesian mindset needs no introduction, and this post is completely inadequete to explain why anyone should be interested (that&amp;rsquo;s what the book is for!</description></item><item><title> "SR2 :: Solutions for Chapters {13,14}"</title><link>/posts/sr2-ch13-ch14/</link><pubDate>Sun, 28 Jun 2020 00:00:00 +0000</pubDate><guid>/posts/sr2-ch13-ch14/</guid><description>Setup details are described here, and the meta-post about these solutions is here.
Materials The summmer course1 is based off of the second edition of Statistical Rethinking by Richard McElreath.
Chapter 13 E{1,2,3,4,5} Chapter 14 E{1,2,3} Packages A colophon with details is provided at the end, but the following packages and theme parameters are used throughout.
1libsUsed&amp;lt;-c(&amp;#34;tidyverse&amp;#34;,&amp;#34;tidybayes&amp;#34;,&amp;#34;orgutils&amp;#34;,&amp;#34;dagitty&amp;#34;, 2 &amp;#34;rethinking&amp;#34;,&amp;#34;tidybayes.rethinking&amp;#34;, 3 &amp;#34;ggplot2&amp;#34;,&amp;#34;kableExtra&amp;#34;,&amp;#34;dplyr&amp;#34;,&amp;#34;glue&amp;#34;, 4 &amp;#34;latex2exp&amp;#34;,&amp;#34;data.table&amp;#34;,&amp;#34;printr&amp;#34;,&amp;#34;devtools&amp;#34;) 5invisible(lapply(libsUsed, library, character.only = TRUE)); 6theme_set(theme_grey(base_size=24)) 7set.</description></item><item><title> "SR2 :: Solutions for Chapters {9,11,12}"</title><link>/posts/sr2-ch9-ch11-ch12/</link><pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate><guid>/posts/sr2-ch9-ch11-ch12/</guid><description>Setup details are described here, and the meta-post about these solutions is here.
Materials The summmer course1 is based off of the second edition of Statistical Rethinking by Richard McElreath. This submission covers the following exercise questions:
Chapter 9 E{3,4,5,6} M{1,2,3} Chapter 11 E{1,2,3,4} M{2,3,4,5,6,8} Chapter 12 E{4} H{1,2} Packages A colophon with details is provided at the end, but the following packages and theme parameters are used throughout.</description></item><item><title>Temporary LaTeX Documents with Orgmode</title><link>/posts/org-arb-tex/</link><pubDate>Fri, 19 Jun 2020 05:07:00 +0000</pubDate><guid>/posts/org-arb-tex/</guid><description>A post on working with transient TeX templates in orgmode without modifying global configurations. This will also serve as a rudimentary introduction to TeX in orgmode.
Background The sad reality of working in a field dominated by institutional actors which do not care for recognizing software development as a skill is that there are often a lot of ugly LaTeX templates1. In particular, often Universities have arbitrary LaTeX templates from the the dark days of 2010 something, which include gratuitous usage of say, natbib instead of biblatex.</description></item><item><title> "SR2 :: Solutions for Chapters {5,6,7}"</title><link>/posts/sr2-ch5-ch6-ch7/</link><pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate><guid>/posts/sr2-ch5-ch6-ch7/</guid><description>Setup details are described here, and the meta-post about these solutions is here.
Materials The summmer course1 is based off of the second edition of Statistical Rethinking by Richard McElreath. This post covers the following exercise questions:
Chapter 5 E{1,2,3,4} M{1,2,3,5} Chapter 6 E{1,2,3,4} M{1,2,3} Chapter 7 E{1,2,3,4} M{1,2,3,4,5,6} Packages A colophon with details is provided at the end, but the following packages and theme parameters are used throughout.</description></item><item><title>Emacs for Nix-R</title><link>/posts/emacs-nix-r/</link><pubDate>Wed, 10 Jun 2020 00:12:00 +0000</pubDate><guid>/posts/emacs-nix-r/</guid><description>A short post on my current set-up for R with nixpkgs and emacs to auto-compile my system configuration.
Background This is my third post on working with nixpkgs and R.
Part I covered ways of working effectively with R and nixpkgs Part II dealt with composing dependent devtools packages in a per-package environment, with a focus on rethinking and tidybayes.rethinking This final part is about automating the system-wide configuration using emacs.</description></item><item><title>Statistical Rethinking and Nix</title><link>/posts/rethinking-r-nix/</link><pubDate>Sun, 07 Jun 2020 04:24:00 +0000</pubDate><guid>/posts/rethinking-r-nix/</guid><description>This post describes how to set up a transparent automated setup for reproducible R workflows using nixpkgs, niv, and lorri. The explanatory example used throughout the post is one of setting up the rethinking package and running some examples from the excellent second edition of &amp;ldquo;Statistical Rethinking&amp;rdquo; by Richard McElreath.
Background As detailed in an earlier post1, I had set up Nix to work with non-CRAN packages. If the rest of this section is unclear, please refer back to the earlier post.</description></item><item><title> "SR2 :: Solutions for Chapters {2,3,4}"</title><link>/posts/sr2-ch2-ch3-ch4/</link><pubDate>Sun, 07 Jun 2020 00:00:00 +0000</pubDate><guid>/posts/sr2-ch2-ch3-ch4/</guid><description>Setup details are described here, and the meta-post about these solutions is here.
Materials The summmer course1 is based off of the second edition of Statistical Rethinking by Richard McElreath. This post covers the following exercise questions:
Chapter 2 Easy {1,2,3,4} Medium {1,2,4} Chapter 3 Easy {1,2,3,4,5} Medium {1,2,3,4,6} Chapter 4 Easy {1,2,3,4,5} Medium {1,2,3,4,5,6,7} Packages 1libsUsed&amp;lt;-c(&amp;#34;tidyverse&amp;#34;,&amp;#34;tidybayes&amp;#34;,&amp;#34;orgutils&amp;#34;, 2 &amp;#34;rethinking&amp;#34;,&amp;#34;tidybayes.rethinking&amp;#34;, 3 &amp;#34;ggplot2&amp;#34;,&amp;#34;kableExtra&amp;#34;,&amp;#34;dplyr&amp;#34;,&amp;#34;glue&amp;#34;, 4 &amp;#34;latex2exp&amp;#34;,&amp;#34;data.table&amp;#34;,&amp;#34;printr&amp;#34;) 5invisible(lapply(libsUsed, library, character.only = TRUE)); We also set the following theme parameters for the plots.</description></item><item><title>Nix with R and devtools</title><link>/posts/nix-r-devtools/</link><pubDate>Sat, 06 Jun 2020 05:49:00 +0000</pubDate><guid>/posts/nix-r-devtools/</guid><description>This post discusses briefly, the nix-shell environment for reproducible programming. In particular, there is an emphasis on extensions for installing and working with packages not in CRAN, i.e. packages off Github which are normally installed with devtools.
Background The entire nix ecosystem is fantastic, and is the main packaging system used by d-SEAMS as well. Recently I began working through the excellent second edition of &amp;ldquo;Statistical Rethinking&amp;rdquo; by Richard McElreath1.</description></item><item><title>An Orgmode Note Workflow</title><link>/posts/org-note-workflow/</link><pubDate>Sun, 10 May 2020 15:01:00 +0000</pubDate><guid>/posts/org-note-workflow/</guid><description>Background One of the main reasons to use orgmode is definitely to get a better note taking workflow. Closely related to blogging or writing, the ideal note workflow is one which lets you keep a bunch of throwaway ideas and also somehow have access to them in a coherent manner. This will be a long post, and it is a work-in-progress, so, keep that in mind. Since this is mainly me1 work-shopping my technique, the philosophy will come in a later post probably.</description></item><item><title>Refactoring Dotfiles For Colemak</title><link>/posts/colemak-dots-refactor/</link><pubDate>Sat, 02 May 2020 20:30:00 +0000</pubDate><guid>/posts/colemak-dots-refactor/</guid><description>A more actionable follow up to my personal recollections relating to my switch to Colemak.
Background I have, in the past written about how I made the switch to Colemak. However, until recently, I was still trying to mimic the VIM keybindings from QWERTY. This is a post where I discuss the changes I made to ensure that I never have to stretch my fingers in odd ways again. The main idea is expressed well by vim-colemak.</description></item><item><title>Pandoc to Orgmode with Babel</title><link>/posts/org-pandoc-babel/</link><pubDate>Sat, 02 May 2020 16:39:00 +0000</pubDate><guid>/posts/org-pandoc-babel/</guid><description>Background One of the best things about writing in orgmode is that we can embed and execute arbitrary code snippets. However, not all languages have an exporter, for obvious reasons. Somewhat surprisingly, there is no way to call pandoc on embedded snippets, which feels like a waste, especially when a whole bunch of documentation formats can be converted to orgmode with it.
Consider the following beautifully highlighted snippet of an rst (ReStructured Text) list table.</description></item><item><title>Using Mathematica with Orgmode</title><link>/posts/org-mathematica/</link><pubDate>Sun, 26 Apr 2020 20:01:00 +0000</pubDate><guid>/posts/org-mathematica/</guid><description>Background I have been wanting to find a workflow which allows me to bypass writing a lot of TeX by hand for a while now. To that end I looked into using a computer algebra system (CAS). Naturally, my first choice was the FOSS Maxima (also because it uses Lisp under the hood). However, for all the reasons listed here, relating to its accuracy, which have not been fixed even though the post was over 5 years ago, I ended up having to go with the closed source Mathematica.</description></item><item><title> "Everyone Should Get an A - David MacKay"</title><link>/posts/mackay-all-a/</link><pubDate>Mon, 16 Mar 2020 02:24:00 +0000</pubDate><guid>/posts/mackay-all-a/</guid><description>Background I recently read this post written by the now deceased Prof. David MacKay 1 It should be read widely, however, given that it is distributed as a ps.gz which is then a .ps file, and thus probably inaccessible to many of the people who should read it, I decided to rework it for native online consumption (there is also a pdf) THIS IS NOT MY CONTENT 2 Now, enjoy the post Everyone Should Get an A Imagine a University – call it Camwick – where all students arrive with straight A grades.</description></item><item><title>Provisioning Dotfiles on an HPC</title><link>/posts/prov-dots/</link><pubDate>Mon, 16 Mar 2020 00:06:00 +0000</pubDate><guid>/posts/prov-dots/</guid><description>Background My dotfiles turned 4 years old a few months ago (since 9th Jan 2017) and remains one of my most frequently updated projects for obvious reasons. Going through the changes reminds me of a whole of posts I never got around to writing.
Anyway, recently I gained access to another HPC cluster, with a standard configuration (bash, old CentOS) and decided to track my provisioning steps. This is really a very streamlined experience by now, since I&amp;rsquo;ve used the same setup across scores of machines.</description></item><item><title> "ISLR :: Moving Beyond Linearity"</title><link>/posts/islr-ch7/</link><pubDate>Wed, 19 Feb 2020 09:47:00 +0000</pubDate><guid>/posts/islr-ch7/</guid><description>Chapter VII - Moving Beyond Linearity All the questions are as per the ISL seventh printing of the First edition1.
Common 1libsUsed&amp;lt;-c(&amp;#34;dplyr&amp;#34;,&amp;#34;ggplot2&amp;#34;,&amp;#34;tidyverse&amp;#34;, 2 &amp;#34;ISLR&amp;#34;,&amp;#34;caret&amp;#34;,&amp;#34;MASS&amp;#34;, &amp;#34;gridExtra&amp;#34;, 3 &amp;#34;pls&amp;#34;,&amp;#34;latex2exp&amp;#34;,&amp;#34;data.table&amp;#34;) 4invisible(lapply(libsUsed, library, character.only = TRUE)) Question 7.6 - Page 299 In this exercise, you will further analyze the Wage data set considered throughout this chapter.
(a) Perform polynomial regression to predict wage using age. Use cross-validation to select the optimal degree d for the polynomial.</description></item><item><title> "ISLR :: Linear Model Selection and Regularization"</title><link>/posts/islr-ch6/</link><pubDate>Wed, 19 Feb 2020 07:00:00 +0000</pubDate><guid>/posts/islr-ch6/</guid><description>Chapter VI - Linear Model Selection and Regularization All the questions are as per the ISL seventh printing of the First edition1.
Common Instead of using the standard functions, we will leverage the mlr3 package2.
1#install.packages(&amp;#34;mlr3&amp;#34;,&amp;#34;data.table&amp;#34;,&amp;#34;mlr3viz&amp;#34;,&amp;#34;mlr3learners&amp;#34;) Actually for R version 3.6.2, the steps to get it working were a bit more involved.
Load ISLR and other libraries.
1libsUsed&amp;lt;-c(&amp;#34;dplyr&amp;#34;,&amp;#34;ggplot2&amp;#34;,&amp;#34;tidyverse&amp;#34;, 2 &amp;#34;ISLR&amp;#34;,&amp;#34;caret&amp;#34;,&amp;#34;MASS&amp;#34;, &amp;#34;gridExtra&amp;#34;, 3 &amp;#34;pls&amp;#34;,&amp;#34;latex2exp&amp;#34;,&amp;#34;data.table&amp;#34;) 4invisible(lapply(libsUsed, library, character.only = TRUE)) Question 6.8 - Page 262 In this exercise, we will generate simulated data, and will then use this data to perform best subset selection.</description></item><item><title> "ISLR :: Resampling Methods"</title><link>/posts/islr-ch5/</link><pubDate>Tue, 18 Feb 2020 22:00:00 +0000</pubDate><guid>/posts/islr-ch5/</guid><description>Chapter V - Resampling Methods All the questions are as per the ISL seventh printing of the First edition1.
Common Instead of using the standard functions, we will leverage the mlr3 package2.
1#install.packages(&amp;#34;mlr3&amp;#34;,&amp;#34;data.table&amp;#34;,&amp;#34;mlr3viz&amp;#34;,&amp;#34;mlr3learners&amp;#34;) Actually for R version 3.6.2, the steps to get it working were a bit more involved.
1install.packages(&amp;#34;remotes&amp;#34;,&amp;#34;data.table&amp;#34;, 2 &amp;#34;GGally&amp;#34;,&amp;#34;precerec&amp;#34;) # For plots 1library(remotes) 2remotes::install_github(&amp;#34;mlr-org/mlr3&amp;#34;) 3remotes::install_github(&amp;#34;mlr-org/mlr3viz&amp;#34;) 4remotes::install_github(&amp;#34;mlr-org/mlr3learners&amp;#34;) Load ISLR and other libraries.
1libsUsed&amp;lt;-c(&amp;#34;dplyr&amp;#34;,&amp;#34;ggplot2&amp;#34;,&amp;#34;tidyverse&amp;#34;, 2 &amp;#34;ISLR&amp;#34;,&amp;#34;caret&amp;#34;,&amp;#34;MASS&amp;#34;, 3 &amp;#34;pROC&amp;#34;,&amp;#34;mlr3&amp;#34;,&amp;#34;data.table&amp;#34;, 4 &amp;#34;mlr3viz&amp;#34;,&amp;#34;mlr3learners&amp;#34;) 5invisible(lapply(libsUsed, library, character.</description></item><item><title> "ISLR :: Classification"</title><link>/posts/islr-ch4/</link><pubDate>Mon, 17 Feb 2020 15:28:00 +0000</pubDate><guid>/posts/islr-ch4/</guid><description>Chapter IV - Classification All the questions are as per the ISL seventh printing of the First edition 1.
Common Stuff Here I&amp;rsquo;ll load things I will be using throughout, mostly libraries.
1libsUsed&amp;lt;-c(&amp;#34;dplyr&amp;#34;,&amp;#34;ggplot2&amp;#34;,&amp;#34;tidyverse&amp;#34;,&amp;#34;ISLR&amp;#34;,&amp;#34;caret&amp;#34;) 2invisible(lapply(libsUsed, library, character.only = TRUE)) Question 4.10 - Page 171 This question should be answered using the Weekly data set, which is part of the ISLR package. This data is similar in nature to the Smarket data from this chapter&amp;rsquo;s lab, except that it contains 1, 089 weekly returns for 21 years, from the beginning of 1990 to the end of 2010.</description></item><item><title>Replacing Jupyter with Orgmode</title><link>/posts/jupyter-orgmode/</link><pubDate>Thu, 13 Feb 2020 22:36:00 +0000</pubDate><guid>/posts/jupyter-orgmode/</guid><description>Background I dislike Jupyter notebooks (and JupyterHub) a lot EIN is really not much of a solution either In the past I have written some posts on TeX with JupyterHub and discussed ways to use virtual Python with JupyterHub in a more reasonable manner.
However, I personally found that EIN was a huge pain to work with, and I mostly ended up working with the web-interface anyway.
It is a bit redundant to do so, given that at-least for my purposes, the end result was a LaTeX document.</description></item><item><title>Poetry and Direnv</title><link>/posts/poetry-direnv/</link><pubDate>Thu, 13 Feb 2020 21:36:00 +0000</pubDate><guid>/posts/poetry-direnv/</guid><description>Background I end up writing about using poetry a lot I almost always use direnv in real life too I don&amp;rsquo;t keep writing mini scripts in my .envrc Honestly there&amp;rsquo;s nothing here anyone using the direnv wiki will find surprising, but then it is still neat to link back to.
Setting Up Poetry This essentially works by simply modifying the global .direnvrc which essentially gets sourced by every local .envrc anyway.</description></item><item><title> "ISLR :: Multiple Linear Regression"</title><link>/posts/islr-ch2-ch3/</link><pubDate>Wed, 15 Jan 2020 05:28:00 +0000</pubDate><guid>/posts/islr-ch2-ch3/</guid><description>Chapter II - Statistical Learning All the questions are as per the ISL seventh printing of the First edition 1.
Question 2.8 - Pages 54-55 This exercise relates to the College data set, which can be found in the file College.csv. It contains a number of variables for \(777\) different universities and colleges in the US. The variables are
Private : Public/private indicator Apps : Number of applications received Accept : Number of applicants accepted Enroll : Number of new students enrolled Top10perc : New students from top 10 % of high school class Top25perc : New students from top 25 % of high school class F.</description></item></channel></rss>